{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JunHL96/PyTorch/blob/main/00_pytorch_fundamentals_notes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaHh2Bjo-wKu"
      },
      "source": [
        "## 00. Pytorch Fundamentals\n",
        "\n",
        "Resource notebook: https://www.learnpytorch.io/00_pytorch_fundamentals/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "Mh5PfyZO-wKv",
        "outputId": "6a81282e-61d5-4953-a9af-b7aaa76bf253"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.5.0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGuQeJfY-wKw"
      },
      "source": [
        "### Device-Agnostic Code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "EUyFABW7-wKw",
        "outputId": "947e7d25-96c6-4cdf-dfab-2b96f4694f26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: mps\n"
          ]
        }
      ],
      "source": [
        "# Setup device-agnostic code\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\" # NVIDIA GPU\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = \"mps\" # Apple GPU\n",
        "else:\n",
        "    device = \"cpu\" # Defaults to CPU if NVIDIA GPU/Apple GPU aren't available\n",
        "\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H73Wlcb-wKw"
      },
      "source": [
        "## What is PyTorch?\n",
        "\n",
        "[PyTorch](https://pytorch.org/) is an open source machine learning and deep learning framework.\n",
        "\n",
        "## What can PyTorch be used for?\n",
        "\n",
        "PyTorch allows you to manipulate and process data and write machine learning algorithms using Python code.\n",
        "\n",
        "## Who uses PyTorch?\n",
        "\n",
        "Many of the world's largest technology companies such as [Meta (Facebook)](https://ai.facebook.com/blog/pytorch-builds-the-future-of-ai-and-machine-learning-at-facebook/), Tesla and Microsoft as well as artificial intelligence research companies such as [OpenAI use PyTorch](https://openai.com/blog/openai-pytorch/) to power research and bring machine learning to their products.\n",
        "\n",
        "![pytorch being used across industry and research](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-pytorch-being-used-across-research-and-industry.png)\n",
        "\n",
        "For example, Andrej Karpathy (head of AI at Tesla) has given several talks ([PyTorch DevCon 2019](https://youtu.be/oBklltKXtDE), [Tesla AI Day 2021](https://youtu.be/j0z4FweCy4M?t=2904)) about how Tesla uses PyTorch to power their self-driving computer vision models.\n",
        "\n",
        "PyTorch is also used in other industries such as agriculture to [power computer vision on tractors](https://medium.com/pytorch/ai-for-ag-production-machine-learning-for-agriculture-e8cfdb9849a1).\n",
        "\n",
        "## Why use PyTorch?\n",
        "\n",
        "Machine learning researchers love using PyTorch. And as of February 2022, PyTorch is the [most used deep learning framework on Papers With Code](https://paperswithcode.com/trends), a website for tracking machine learning research papers and the code repositories attached with them.\n",
        "\n",
        "PyTorch also helps take care of many things such as GPU acceleration (making your code run faster) behind the scenes.\n",
        "\n",
        "So you can focus on manipulating data and writing algorithms and PyTorch will make sure it runs fast.\n",
        "\n",
        "And if companies such as Tesla and Meta (Facebook) use it to build models they deploy to power hundreds of applications, drive thousands of cars and deliver content to billions of people, it's clearly capable on the development front too.\n",
        "\n",
        "## What we're going to cover in this module\n",
        "\n",
        "This course is broken down into different sections (notebooks).\n",
        "\n",
        "Each notebook covers important ideas and concepts within PyTorch.\n",
        "\n",
        "Subsequent notebooks build upon knowledge from the previous one (numbering starts at 00, 01, 02 and goes to whatever it ends up going to).\n",
        "\n",
        "This notebook deals with the basic building block of machine learning and deep learning, the tensor.\n",
        "\n",
        "Specifically, we're going to cover:\n",
        "\n",
        "| **Topic** | **Contents** |\n",
        "| ----- | ----- |\n",
        "| **Introduction to tensors** | Tensors are the basic building block of all of machine learning and deep learning. |\n",
        "| **Creating tensors** | Tensors can represent almost any kind of data (images, words, tables of numbers). |\n",
        "| **Getting information from tensors** | If you can put information into a tensor, you'll want to get it out too. |\n",
        "| **Manipulating tensors** | Machine learning algorithms (like neural networks) involve manipulating tensors in many different ways such as adding, multiplying, combining. |\n",
        "| **Dealing with tensor shapes** | One of the most common issues in machine learning is dealing with shape mismatches (trying to mix wrong shaped tensors with other tensors). |\n",
        "| **Indexing on tensors** | If you've indexed on a Python list or NumPy array, it's very similar with tensors, except they can have far more dimensions. |\n",
        "| **Mixing PyTorch tensors and NumPy** | PyTorch plays with tensors ([`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html)), NumPy likes arrays ([`np.ndarray`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.html)) sometimes you'll want to mix and match these. |\n",
        "| **Reproducibility** | Machine learning is very experimental and since it uses a lot of *randomness* to work, sometimes you'll want that *randomness* to not be so random. |\n",
        "| **Running tensors on GPU** | GPUs (Graphics Processing Units) make your code faster, PyTorch makes it easy to run your code on GPUs. |\n",
        "\n",
        "## Where can you get help?\n",
        "\n",
        "All of the materials for this course [live on GitHub](https://github.com/mrdbourke/pytorch-deep-learning).\n",
        "\n",
        "And if you run into trouble, you can ask a question on the [Discussions page](https://github.com/mrdbourke/pytorch-deep-learning/discussions) there too.\n",
        "\n",
        "There's also the [PyTorch developer forums](https://discuss.pytorch.org/), a very helpful place for all things PyTorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlWXYet2-wKw"
      },
      "source": [
        "## Introduction to Tensors\n",
        "\n",
        "### What are tensors?\n",
        "\n",
        "A tensor is a multi-dimensional matrix containing elements of a single data type.\n",
        "\n",
        "### Creating tensors\n",
        "\n",
        "PyTorch tensors are created using 'torch.tensor()' = https://pytorch.org/docs/stable/tensors.html\n",
        "\n",
        "\n",
        "For example, you could represent an image as a tensor with shape `[3, 224, 224]` which would mean `[colour_channels, height, width]`, as in the image has `3` colour channels (red, green, blue), a height of `224` pixels and a width of `224` pixels.\n",
        "\n",
        "![example of going from an input image to a tensor representation of the image, image gets broken down into 3 colour channels as well as numbers to represent the height and width](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-tensor-shape-example-of-image.png)\n",
        "\n",
        "In tensor-speak (the language used to describe tensors), the tensor would have three dimensions, one for `colour_channels`, `height` and `width`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "xRvp4BO3-wKw",
        "outputId": "35e4dc3a-9e95-4ce3-d3e0-ad8c8fdf10be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(7, device='mps:0')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# scalar\n",
        "scalar = torch.tensor(7, device = device)\n",
        "scalar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "lM7_5FhB-wKx",
        "outputId": "6e1d03ea-0a2d-4344-a4e9-649ad6fef91f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scalar.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "ninudjgL-wKx",
        "outputId": "0fe3394e-96a6-46a3-f246-1c81593d77c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get tensor back as Python int\n",
        "scalar.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "nqH0b04S-wKx",
        "outputId": "d9da22cc-f8ce-491e-b469-ed34e5c50e83"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([7, 7], device='mps:0')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Vector (magnitude, direction)\n",
        "vector = torch.tensor([7, 7], device = device)\n",
        "vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "3TXdxp7J-wKx",
        "outputId": "cc049882-13c6-4174-9038-2297ce4ec5d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "BM2oWFno-wKx",
        "outputId": "ddcedcbd-634b-48fb-e3e5-1f8823906ff3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU8kZ1LC-wKx"
      },
      "source": [
        "<details>\n",
        "\n",
        "### `.shape`\n",
        "- **Returns the dimensions of the tensor (or array)** as a tuple.\n",
        "- Each element of the tuple (an ordered, immutable collection of items) represents the size of the tensor in that dimension.\n",
        "\n",
        "Example:\n",
        "```python\n",
        "vector = torch.tensor([7, 7])\n",
        "print(vector.shape)  # Output: torch.Size([2])\n",
        "```\n",
        "\n",
        "### `.ndim`\n",
        "- **Returns the number of dimensions (rank) of the tensor.**\n",
        "- this is an integer value representing how many dimensions the tensor has\n",
        "\n",
        "Example:\n",
        "```python\n",
        "vector = torch.tensor([7, 7])\n",
        "print(vector.ndim)  # Output: 1\n",
        "```\n",
        "\n",
        "### Explanation:\n",
        "- `vector = torch.tensor([7, 7])` creates a 1D tensor (vector) with 2 elements.\n",
        "- `.shape` gives `(2)` because the vector has 2 elements in one dimension.\n",
        "- `.ndim` gives `1` because the tensor is 1-dimensional.\n",
        "\n",
        "\n",
        "| Attribute  | Description                               | Example Output            |\n",
        "|------------|-------------------------------------------|---------------------------|\n",
        "| `.shape`   | Tuple representing the size of each dimension | `torch.Size([2])`   |\n",
        "| `.ndim`    | Integer representing the number of dimensions | `1`                       |\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KifTlwc-wKy"
      },
      "source": [
        "## Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "SA_k7HXi-wKy"
      },
      "outputs": [],
      "source": [
        "# MATRIX\n",
        "MATRIX = torch.tensor([[7, 8],\n",
        "                      [9, 10]], device = device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "niVij1s2-wKy",
        "outputId": "9063510e-f967-4b60-ebbc-ce9bf88013d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MATRIX.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "XkM_o6CR-wKy",
        "outputId": "7fbc4e12-475f-4223-8b41-c46adb3d2c19"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([7, 8], device='mps:0')"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MATRIX[0] # index on 0th axis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "W0jh7a-v-wKy",
        "outputId": "cece8bb7-4917-4f94-b6ec-650dd646d99d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 9, 10], device='mps:0')"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MATRIX[1] # index on 1st axis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "pPjjHt6_-wKy",
        "outputId": "0678ad44-8427-4ead-fd33-68786dda43ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MATRIX.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUeEs1Ik-wKy"
      },
      "source": [
        "## Tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "92mauBx_-wKy",
        "outputId": "83da5568-c615-4d32-c258-59c714c7d2cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[1, 2, 3],\n",
              "         [3, 6, 9],\n",
              "         [2, 4, 5]]], device='mps:0')"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TENSOR\n",
        "TENSOR = torch.tensor([[[1, 2, 3],\n",
        "                        [3, 6, 9],\n",
        "                        [2, 4, 5]]], device = device)\n",
        "TENSOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "hRQXEZZx-wKy",
        "outputId": "114e9c12-5ce9-4091-9694-0fb1462552ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TENSOR.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "5rX8ii-S-wKy",
        "outputId": "2dae2093-bf8e-4a9b-838a-041921c8f9af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 3])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TENSOR.shape # the result is torch.Size([1, 3, 3]), meaning we have one dimension of 3x3 tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "er78Kjb1-wKy"
      },
      "source": [
        "### Image Representation\n",
        "![example of different tensor dimensions](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-pytorch-different-tensor-dimensions.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "_uHrSTUj-wKy",
        "outputId": "f1dc8743-2389-4b5c-e9cb-fa2d6277c2bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [3, 6, 9],\n",
              "        [2, 4, 5]], device='mps:0')"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TENSOR[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHsIlMCY-wKy"
      },
      "source": [
        "### Summarization so far\n",
        "\n",
        "| Name | What is it? | Number of dimensions | Lower or upper (usually/example) |\n",
        "| ----- | ----- | ----- | ----- |\n",
        "| **scalar** | a single number | 0 | Lower (`a`) |\n",
        "| **vector** | a number with direction (e.g. wind speed with direction) but can also have many other numbers | 1 | Lower (`y`) |\n",
        "| **matrix** | a 2-dimensional array of numbers | 2 | Upper (`Q`) |\n",
        "| **tensor** | an n-dimensional array of numbers | can be any number, a 0-dimension tensor is a scalar, a 1-dimension tensor is a vector | Upper (`X`) |\n",
        "\n",
        "![scalar vector matrix tensor and what they look like](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-scalar-vector-matrix-tensor.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoYuzsKL-wKy"
      },
      "source": [
        "## Random Tensors\n",
        "\n",
        "### Why Random Tensors?\n",
        "Random tensors are important b/c the way many neural networks learn is that they start with tensors full of random numbers and then adjust those random numbers to better represent the data.\n",
        "\n",
        "`Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers`\n",
        "\n",
        "### Documentation of torch.rand\n",
        "https://pytorch.org/docs/stable/generated/torch.rand.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "K3baR5vZ-wKy",
        "outputId": "f3f8b269-d3c3-4dfb-e984-dec4b114c960"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.7467, 0.0097, 0.0881, 0.1962],\n",
              "        [0.6511, 0.3817, 0.8581, 0.2633],\n",
              "        [0.6535, 0.2196, 0.4270, 0.3614]], device='mps:0')"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a random tensor of size (3, 4)\n",
        "\n",
        "random_tensor = torch.rand(3, 4, device=device)\n",
        "#random_tensor = torch.rand(5, 10, 10, device=mps)\n",
        "random_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "SGWamsOT-wKy",
        "outputId": "0919fdb2-c12c-454f-d9f7-b57470f0e25d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random_tensor.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "yf1OkYXV-wKy",
        "outputId": "c86debac-964e-462b-a852-f57bf9ebbeac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([224, 224, 3]), 3)"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a random tensor with similar shape to an image tensor\n",
        "random_image_size_tensor = torch.rand(size=(224, 224, 3), device=device) # height, width, color channels (R, G, B)\n",
        "random_image_size_tensor.shape, random_image_size_tensor.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiFlXgJE-wKy"
      },
      "source": [
        "### Zeroes and Ones Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "bQNkU_w_-wKz",
        "outputId": "2d5ef6c4-719f-4139-d910-f483d5fc4df4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor of all zeros\n",
        "zeros = torch.zeros(size=(3, 4))\n",
        "zeros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "R7VvlTmr-wKz",
        "outputId": "2442559e-f6ff-46a0-931e-f76ac3ea4dda"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor of all ones\n",
        "ones = torch.ones(size=(3, 4))\n",
        "ones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "BhoDA4l--wKz",
        "outputId": "a64e493a-b471-4f66-bc3a-ce2c9cb5c6d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random_tensor.dtype # check data type of tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7KEMJfe-wKz"
      },
      "source": [
        "## Creating a range of tensors and tensors-like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "pFTMZRvO-wKz",
        "outputId": "4e8ba5b8-46f8-4b3d-b6ae-d1aa31eb247c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10], device='mps:0')"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Use torch.arange()\n",
        "one_to_ten = torch.arange(start=1, end=11, step = 1, device=device)\n",
        "one_to_ten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "f0EcnCcu-wKz",
        "outputId": "8925d464-a61d-4511-c4ba-10e587fb3f16"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='mps:0')"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Creating tensors-like\n",
        "ten_zeros = torch.zeros_like(input=one_to_ten) # the zeros_like function creates a new tensor with same shape as the input\n",
        "ten_zeros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huzVklG--wKz"
      },
      "source": [
        "## Tensor Datatypes\n",
        "\n",
        "**Note:** Tensor datatypes is one of the 3 big potential errors you'll run into with PyTorch & Deep Learning:\n",
        "1. Tensors are not the right datatype\n",
        "2. Tensors are not the right shape\n",
        "3. Tensors are not on the right device (such as cpu, cuda, mps, etc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "xqccbkSh-wKz",
        "outputId": "df63219f-aa4e-430d-ae95-4197659f9c61"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([3., 6., 9.], device='mps:0')"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Float 32 tensor\n",
        "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                               dtype=None,  # what datatype is the tensor (e.g. float32, float16)\n",
        "                               device=device, # What device is your tensor on\n",
        "                               requires_grad=False) # whether or not to track gradients with this tensors operation\n",
        "float_32_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "CvKvRzC0-wK2",
        "outputId": "1d695fe1-9e24-49ba-a513-3ae31cb7177d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "float_32_tensor.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "cT1Cq5n8-wK2",
        "outputId": "87ba79b8-bd23-434b-b4fe-28f6824d8305"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([3., 6., 9.], device='mps:0', dtype=torch.float16)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "float_16_tensor = float_32_tensor.type(torch.float16)\n",
        "float_16_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "CCLcFIJk-wK2",
        "outputId": "18faa2d6-077c-48a9-b7d5-27e2c4503b89"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([3, 6, 9], device='mps:0', dtype=torch.int32)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "int_32_tensor = torch.tensor([3, 6, 9], dtype=torch.int32, device=device)\n",
        "int_32_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZPPuG0M-wK2"
      },
      "source": [
        "### Getting Information from Tensors\n",
        "\n",
        "1. Tensors are not the right datatype - to get detatype from a tensor, can use `tensor.dtype`\n",
        "2. Tensors are not the right shape - to get shape from a tensor, can use `tensor.shape`\n",
        "3. Tensors are not on the right device - to get device from a tensor, can use `tensor.device`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "-Fe5O3K4-wK2"
      },
      "outputs": [],
      "source": [
        "# Create a tensor to get information from\n",
        "test_tensor1 = torch.rand(3, 4, dtype=torch.float64)\n",
        "test_tensor2 = torch.rand(3, 4, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "29oXkGgu-wK2",
        "outputId": "461e9c09-92e1-4050-fe33-5e26ff8018d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.7209, 0.8423, 0.2945, 0.9707],\n",
            "        [0.9395, 0.1181, 0.4804, 0.5916],\n",
            "        [0.8457, 0.7156, 0.0367, 0.4763]], dtype=torch.float64)\n",
            "Datatype of tensor1: torch.float64\n",
            "Datatype of tensor2: torch.float32\n",
            "Shape of tensor: torch.Size([3, 4])\n",
            "Device tensor1 is on: cpu\n",
            "Device tensor2 is on: mps:0\n"
          ]
        }
      ],
      "source": [
        "# Find out information\n",
        "print(test_tensor1)\n",
        "print(f\"Datatype of tensor1: {test_tensor1.dtype}\")\n",
        "print(f\"Datatype of tensor2: {test_tensor2.dtype}\")\n",
        "print(f\"Shape of tensor: {test_tensor1.shape}\")\n",
        "print(f\"Device tensor1 is on: {test_tensor1.device}\")\n",
        "print(f\"Device tensor2 is on: {test_tensor2.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plnA4CQb-wK2"
      },
      "source": [
        "### Manipulating Tensors (Tensor Operations)\n",
        "\n",
        "Tensor operations include:\n",
        "* Addition\n",
        "* Subtraction\n",
        "* Multiplication (element-wise)\n",
        "* Division\n",
        "* Matrix Multiplication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "ZuEsdRss-wK3",
        "outputId": "810a30f4-17a8-4097-ff7c-2b906457b692"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([11, 12, 13], device='mps:0')"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor\n",
        "tensor = torch.tensor([1, 2, 3], device=device)\n",
        "tensor + 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "Herj_q6_-wK3",
        "outputId": "31b3dc1d-bb28-4979-a5ba-82171e27b4ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([10, 20, 30], device='mps:0')"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Multiply tensor by 10\n",
        "tensor * 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "0CXcIeRP-wK3",
        "outputId": "e09e11e4-2f23-472b-8fd8-f78c31fa78cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-9, -8, -7], device='mps:0')"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Subtract by 10\n",
        "tensor - 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "6uKFNmF4-wK3",
        "outputId": "7a2a493f-3e86-4091-9164-3a1c0be34d61"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([10, 20, 30], device='mps:0')"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Try out Pytorch in-built functions\n",
        "torch.mul(tensor, 10) # Generally, you want to use Python functions instead"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "tt66laYz-wK3",
        "outputId": "edf4798a-ee41-44e9-f873-b1a8f3f1a1e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([11, 12, 13], device='mps:0')"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.add(tensor, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIz4AMTa-wK3"
      },
      "source": [
        "### Matrix Multiplication\n",
        "\n",
        "Two main ways of performing multiplication in neural networks and deep learning:\n",
        "\n",
        "1. Element-wise multiplication\n",
        "2. Matrix multiplication (dot-product)\n",
        "\n",
        "The main two rules for matrix multiplication to remember are:\n",
        "\n",
        "* The inner dimensions must match: \\\\\n",
        "(3, 2) @ (3, 2) won't work \\\\\n",
        "(2, 3) @ (3, 2) will work \\\\\n",
        "(3, 2) @ (2, 3) will work \\\\\n",
        "* The resulting matrix has the shape of the outer dimensions: \\\\\n",
        "(2, 3) @ (3, 2) -> (2, 2) \\\\\n",
        "(3, 2) @ (2, 3) -> (3, 3)\n",
        "\n",
        "```\n",
        "Note: \"@\" in Python is the symbol for matrix multiplication.\n",
        "```\n",
        "```\n",
        "Resource: You can see all of the rules for matrix multiplication using torch.matmul() in the PyTorch documentation.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "NJRV0sVo-wK3",
        "outputId": "45868a73-8418-4a76-b5cb-5a141b22e26f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1, 2, 3], device='mps:0') * tensor(1, device='mps:0') tensor(2, device='mps:0') tensor(3, device='mps:0')\n",
            "Equals: tensor([1, 4, 9], device='mps:0')\n"
          ]
        }
      ],
      "source": [
        "# Element-wise multiplication\n",
        "print(tensor, \"*\", * tensor)\n",
        "print(f\"Equals: {tensor * tensor}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "Inv2koJM-wK3",
        "outputId": "144b01d8-f9ea-499b-84a4-830cd23f36ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(14., device='mps:0')"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Matrix Multiplication\n",
        "\n",
        "tensor = tensor.float() # currently, MPS device only supports float32\n",
        "torch.matmul(tensor, tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "giOBc_M4-wK3",
        "outputId": "b95f2e8e-83b3-4b21-8d8a-a68faa34dc4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(14., device='mps:0')\n",
            "CPU times: user 9.93 ms, sys: 2.27 ms, total: 12.2 ms\n",
            "Wall time: 12.9 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "value = 0\n",
        "for i in range(len(tensor)):\n",
        "    value += tensor[i] * tensor[i]\n",
        "print(value)\n",
        "# Matrix multiplication by hand\n",
        "# Don't use for loops in PyTorch b/c they are computationally expensive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "X0kH1cR3-wK3",
        "outputId": "d0afa5e0-f583-4098-a504-6ca0a3a2e311"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 194 μs, sys: 59 μs, total: 253 μs\n",
            "Wall time: 131 μs\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(14., device='mps:0')"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "torch.matmul(tensor, tensor)\n",
        "\n",
        "# we see that the in-built function is much more optimized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "bW6w9LwM-wK3",
        "outputId": "64800be6-9732-45d0-b0dc-743f3201db0a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.6396, 0.5466, 0.5008],\n",
              "        [1.0496, 0.9113, 0.8535],\n",
              "        [0.9927, 0.8652, 0.8144]], device='mps:0')"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.matmul(torch.rand(3, 2, device=device), torch.rand(2, 3, device=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "XpsxY039-wK3",
        "outputId": "f432497a-9f4a-474f-a0eb-2ae675cd6359"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1.7733, 2.7598, 1.7407],\n",
              "        [1.6163, 2.2521, 2.3059]], device='mps:0')"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.matmul(torch.rand(2, 10, device=device), torch.rand(10, 3, device=device))\n",
        "\n",
        "# remember: resulting matrix has the shape of the outer dimensions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmLOTe2l-wK3"
      },
      "source": [
        "### One of the most common errors in Deep Learning: Shape Errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "HwGendEf-wK3"
      },
      "outputs": [],
      "source": [
        "# Shapes for matrix multiplication\n",
        "tensor_A = torch.tensor([[1, 2],\n",
        "                         [3, 4],\n",
        "                         [5, 6]])\n",
        "\n",
        "tensor_B = torch.tensor([[7, 10],\n",
        "                         [8, 11],\n",
        "                         [9, 12]])\n",
        "\n",
        "\n",
        "# torch.mm(tensor_A, tensor_B) # torch.mm is the same as torch.matmul (alias)\n",
        "#torch.matmul(tensor_A, tensor_B) # uncomment this to get an error because shapes are incompatible"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "STL6uVln-wK3",
        "outputId": "88c5b0bc-05f3-4a9f-d2bd-020de28c99e6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([3, 2]), torch.Size([3, 2]))"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check tensor sizes to make sure they are compatible for matrix multiplication\n",
        "tensor_A.shape, tensor_B.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liHNVId3-wK3"
      },
      "source": [
        "To fix our tensor shape issues, we can manipulate the shape of one of our tensors using a transpose.\n",
        "\n",
        "A **transpose** switches the axes or dimensions of a given tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "2lU5mlSg-wK3",
        "outputId": "938183b7-e9af-49b1-a0ab-be206e6d79da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 7, 10],\n",
              "        [ 8, 11],\n",
              "        [ 9, 12]])"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "JP3Y9crn-wK4",
        "outputId": "90afaecc-4172-4c95-9aba-f9833618fc17"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 7,  8,  9],\n",
              "         [10, 11, 12]]),\n",
              " torch.Size([2, 3]))"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_B.T, tensor_B.T.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "2ICYEUKV-wK4",
        "outputId": "70f8ed76-d8c9-4ddb-d148-728600c8359f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 7,  8,  9],\n",
              "         [10, 11, 12]]),\n",
              " torch.Size([2, 3]))"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# transpose switches the dimensions from 3x2 to 2x3\n",
        "tensor_B.T, tensor_B.T.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "J5tCIW65-wK4",
        "outputId": "b4a63c7e-172c-4d5c-ac04-313e68ff3d24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
            "\n",
            "New shapes: tensor_A = torch.Size([3, 2]) (same shape as above), tensor_B.T = torch.Size([2, 3])\n",
            "\n",
            "Multiplying: torch.Size([3, 2]) @ torch.Size([2, 3]) <- inner dimensions must match\n",
            "\n",
            "Output:\n",
            "tensor([[ 27,  30,  33],\n",
            "        [ 61,  68,  75],\n",
            "        [ 95, 106, 117]])\n",
            "\n",
            "Output shape: torch.Size([3, 3])\n"
          ]
        }
      ],
      "source": [
        "# The matrix multiplication operation works when tensor_B is transposed\n",
        "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\\n\")\n",
        "print(f\"New shapes: tensor_A = {tensor_A.shape} (same shape as above), tensor_B.T = {tensor_B.T.shape}\\n\")\n",
        "print(f\"Multiplying: {tensor_A.shape} @ {tensor_B.T.shape} <- inner dimensions must match\\n\")\n",
        "print(\"Output:\")\n",
        "output = torch.matmul(tensor_A, tensor_B.T)\n",
        "print(output)\n",
        "print(f\"\\nOutput shape: {output.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qUv2-g0g-wK4"
      },
      "source": [
        "## Finding the min, max, mean, sum, etc (tensor aggregation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "-6sEz76h-wK4",
        "outputId": "08a85f26-ff19-4fa8-8db3-900ffde90557"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91]), torch.int64)"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor\n",
        "x = torch.arange(1, 100, 10) # torch.arange(start, end, step)\n",
        "x, x.dtype\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "hh18b3VR-wK4",
        "outputId": "9d79f63c-e6de-4b11-f872-6f901b7be62c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(1), tensor(1))"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find the min, note that both torch.sum(x) and x.sum() are functionally equivalent\n",
        "torch.min(x), x.min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "CccsoilI-wK4",
        "outputId": "6cb57511-a2c4-404f-d503-be70d6b2199b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(91), tensor(91))"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find the max\n",
        "torch.max(x), x.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "bYe6c6Cz-wK4",
        "outputId": "e503e537-1eff-4e42-bf21-5de2074cd0ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(46.), tensor(46.))"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find the mean\n",
        "#torch.mean(x), x.mean() # This will result in an error because x is not a float tensor\n",
        "\n",
        "# the torch.mean() function requires a tensor of float32 dtype to work properly\n",
        "torch.mean(x.type(torch.float32)), x.type(torch.float32).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "a5GU-w2d-wK4",
        "outputId": "5cdb7a6b-d82e-49eb-f729-2eacc8f62526"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(460), tensor(460))"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find the sum\n",
        "torch.sum(x), x.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMSBAATm-wK4"
      },
      "source": [
        "## Finding the positional min and max"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "l-NU5OVQ-wK4",
        "outputId": "934fd71e-a052-473a-93cb-1d0b27658563"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0)"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find the position in tensor that has the minimum value with argmin()\n",
        "x.argmin() # This returns index position of target tensor where the minimum value occurs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "_DMUv0Yp-wK4",
        "outputId": "0033fa2b-51a1-45f7-adf1-e5b3032ef531"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x[0] # This returns the actual minimum value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "LFThNDAW-wK4",
        "outputId": "278b6dff-f189-4360-fd8f-5f325f6445d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(9)"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find the position in tensor that has the maximum value with argmax()\n",
        "x. argmax()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "rEUwwGKX-wK4",
        "outputId": "eb057e5c-6c1a-42e6-f126-69e33a9da90a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(91)"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x[9] # This returns the actual maximum value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TooZUMxV-wK4"
      },
      "source": [
        "## Reshaping, stacking, squeezing and unsqueezing tensors\n",
        "Often times you'll want to reshape or change the dimensions of your tensors without actually changing the values inside them.\n",
        "\n",
        "To do so, some popular methods are:\n",
        "\n",
        "| Method | One-line description |\n",
        "| ----- | ----- |\n",
        "| [`torch.reshape(input, shape)`](https://pytorch.org/docs/stable/generated/torch.reshape.html#torch.reshape) | Reshapes `input` to `shape` (if compatible), can also use `torch.Tensor.reshape()`. |\n",
        "| [`Tensor.view(shape)`](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html) | Returns a view of the original tensor in a different `shape` but shares the same data as the original tensor. |\n",
        "| [`torch.stack(tensors, dim=0)`](https://pytorch.org/docs/1.9.1/generated/torch.stack.html) | Concatenates a sequence of `tensors` along a new dimension (`dim`), all `tensors` must be same size. |\n",
        "| [`torch.squeeze(input)`](https://pytorch.org/docs/stable/generated/torch.squeeze.html) | Squeezes `input` to remove all the dimenions with value `1`. |\n",
        "| [`torch.unsqueeze(input, dim)`](https://pytorch.org/docs/1.9.1/generated/torch.unsqueeze.html) | Returns `input` with a dimension value of `1` added at `dim`. |\n",
        "| [`torch.permute(input, dims)`](https://pytorch.org/docs/stable/generated/torch.permute.html) | Returns a *view* of the original `input` with its dimensions permuted (rearranged) to `dims`. |\n",
        "\n",
        "Why do any of these?\n",
        "\n",
        "Because deep learning models (neural networks) are all about manipulating tensors in some way. And because of the rules of matrix multiplication, if you've got shape mismatches, you'll run into errors. These methods help you make sure the right elements of your tensors are mixing with the right elements of other tensors.\n",
        "\n",
        "Let's try them out.\n",
        "\n",
        "First, we'll create a tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "ATRfJlW9-wK4",
        "outputId": "a649b884-57bb-4323-8852-0d51b7f8b3d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor\n",
        "x = torch.arange(1., 10.)\n",
        "x, x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "TcoSGVEH-wK4",
        "outputId": "df7f8d9b-f4d3-46ee-b48b-6eb4a6771143"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[1.],\n",
              "         [2.],\n",
              "         [3.],\n",
              "         [4.],\n",
              "         [5.],\n",
              "         [6.],\n",
              "         [7.],\n",
              "         [8.],\n",
              "         [9.]]),\n",
              " torch.Size([9, 1]))"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Add an extra dimension to the tensor\n",
        "\n",
        "# x.reshape(dim1, dim2, ..., dimN) # Dimension must have the same number of elements as the original tensor, same number as what torch.Size gives\n",
        "#x_reshaped = x.reshape(1, 7) # Error occurs because reshaping to (1, 7) is invalid as the total number of elements must remain the same.\n",
        "#x_reshaped = x.reshape(2, 9) # Error occurs because this would require 18 elements, but we only have 9.\n",
        "x_reshaped = x.reshape(9, 1)\n",
        "x_reshaped, x_reshaped.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "k5MFftlM-wK4",
        "outputId": "f88dc685-0bdb-44dd-d6b2-992b8c07cdb9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Change the view\n",
        "z = x.view(1, 9)\n",
        "z, z.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "k7kKRnTW-wK5",
        "outputId": "bb87d566-71ea-4f34-cfd7-8ae12867da47"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
              " tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]))"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Changing z changes x (because a view of a tensor shares the same memory as the original tensor)\n",
        "z[:, 0] = 5 # This changes the first element of z to 5\n",
        "z, x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "zYe-TQhQ-wK5",
        "outputId": "dd2a841a-0f1b-4d7e-c9d7-07bca31553b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "        [5., 2., 3., 4., 5., 6., 7., 8., 9.]])"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Stack tensors on top of each other\n",
        "\n",
        "# Stack tensors on top of each other along the first dimension (rows), creating a 2D tensor.\n",
        "x_stacked = torch.stack([x, x, x, x], dim=0)\n",
        "\n",
        "# Stack tensors side by side along the second dimension (columns), creating a 2D tensor.\n",
        "#x_stacked = torch.stack([x, x, x, x], dim=1)\n",
        "\n",
        "# Attempt to stack tensors along the third dimension, but this will result in an error for 1D tensors.\n",
        "#x_stacked = torch.stack([x, x, x, x], dim=2)\n",
        "\n",
        "x_stacked\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "JOCF5baJ-wK5",
        "outputId": "198a97b2-efbc-4fd1-f912-9d6b2940ec05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Previous tensor: tensor([[5.],\n",
            "        [2.],\n",
            "        [3.],\n",
            "        [4.],\n",
            "        [5.],\n",
            "        [6.],\n",
            "        [7.],\n",
            "        [8.],\n",
            "        [9.]])\n",
            "Previous shape: torch.Size([9, 1])\n",
            "\n",
            "New tensor: tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
            "New shape: torch.Size([9])\n"
          ]
        }
      ],
      "source": [
        "# torch.squeeze(input, dim=None) - removes all single dimensions from a target tensor\n",
        "print(f\"Previous tensor: {x_reshaped}\")\n",
        "print(f\"Previous shape: {x_reshaped.shape}\")\n",
        "\n",
        "# Remove extra dimensions from x_reshaped\n",
        "x_squeezed = x_reshaped.squeeze()\n",
        "print(f\"\\nNew tensor: {x_squeezed}\")\n",
        "print(f\"New shape: {x_squeezed.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "Jcb-eZnT-wK5",
        "outputId": "205acba0-b767-4971-f0b9-9c81b4e1eadb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Previous target: tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
            "Previous shape: torch.Size([9])\n",
            "\n",
            "New tensor: tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
            "New shape: torch.Size([1, 9])\n"
          ]
        }
      ],
      "source": [
        "# torch.unsqueeze(input, dim) - adds a single dimension to a target tensor at a specific dim\n",
        "print(f\"Previous target: {x_squeezed}\")\n",
        "print(f\"Previous shape: {x_squeezed.shape}\")\n",
        "\n",
        "# Add an extra dimension with unsqueeze\n",
        "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
        "print(f\"\\nNew tensor: {x_unsqueezed}\")\n",
        "print(f\"New shape: {x_unsqueezed.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "CrIqhH-N-wK5",
        "outputId": "47b953db-85ce-446a-d1c7-fe6437596040"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Previous target: tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
            "Previous shape: torch.Size([9])\n",
            "\n",
            "New tensor: \n",
            "tensor([[5.],\n",
            "        [2.],\n",
            "        [3.],\n",
            "        [4.],\n",
            "        [5.],\n",
            "        [6.],\n",
            "        [7.],\n",
            "        [8.],\n",
            "        [9.]])\n",
            "New shape: torch.Size([9, 1])\n"
          ]
        }
      ],
      "source": [
        "# torch.unsqueeze(input, dim) - adds a single dimension to a target tensor at a specific dim\n",
        "print(f\"Previous target: {x_squeezed}\")\n",
        "print(f\"Previous shape: {x_squeezed.shape}\")\n",
        "\n",
        "# Add an extra dimension with unsqueeze\n",
        "x_unsqueezed = x_squeezed.unsqueeze(dim=1)\n",
        "print(f\"\\nNew tensor: \\n{x_unsqueezed}\")\n",
        "print(f\"New shape: {x_unsqueezed.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "1U9qkt3u-wK5",
        "outputId": "27d16152-65fb-4420-ce3e-633dfc8ef745"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Previous shape: torch.Size([224, 224, 3])\n",
            "New shape: torch.Size([3, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "# torch.permute - rearranges the dimensions of a target tensor of a specified order\n",
        "x_original = torch.rand(size=(224, 224, 3)) # [height, width, color_channels]\n",
        "\n",
        "# Permute the original tensor to rearrange the axis order\n",
        "x_permuted = x_original.permute(2, 0, 1) # shifts axis 0->1, 1->2, 2->0\n",
        "\n",
        "print(f\"Previous shape: {x_original.shape}\")\n",
        "print(f\"New shape: {x_permuted.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_lXSlgE-wK5"
      },
      "source": [
        "Remember the purpose of reshaping, stacking, squeezing, and unsqueezing tensors: these help us fix shape and dimension issues with tensors, which is the most common error in Deep Learning and Neural Networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZifDoDf-wK5"
      },
      "source": [
        "## Indexing (selecting data from tensors)\n",
        "\n",
        "Indexing with PyTorch is similar to indexing with NumPy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "Yz_sTTFM-wK5",
        "outputId": "f8f78f85-609f-4fa8-e3b4-eabd3c0fdf5d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[[1, 2, 3],\n",
              "          [4, 5, 6],\n",
              "          [7, 8, 9]]]),\n",
              " torch.Size([1, 3, 3]))"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor\n",
        "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
        "x, x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "kUFt_g_e-wK5",
        "outputId": "cbc509c1-f1b1-4143-a5fc-684cb1101b85"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[1, 2, 3],\n",
              "         [4, 5, 6],\n",
              "         [7, 8, 9]]),\n",
              " torch.Size([3, 3]))"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's index on our new tensor\n",
        "x[0], x[0].shape # Indexing on the first dimension (batch dimension)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "_SaMYhQ3-wK5",
        "outputId": "89a857bb-d3f3-4fa4-a774-eceeaca641b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([1, 2, 3]), torch.Size([3]))"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's index on the middle bracket (dim=1)\n",
        "x[0][0], x[0][0].shape # Indexing on the second dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "12NNDFdi-wK5",
        "outputId": "bb326397-5f27-464b-a0b9-9fa5f1199a63"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(1), torch.Size([]))"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's index on the most inner bracket (last dimension)\n",
        "x[0][0][0], x[0][0][0].shape # Indexing on the third dimension\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "HAD-XpQh-wK5",
        "outputId": "b2d4800e-002d-47d1-b308-d209e1d91ee2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(9), torch.Size([]))"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Play around with the indexing!\n",
        "x[0][2][2], x[0][2][2].shape # note that for our current tensor, x[1][0][0] will give us an error b/c the index is out of bounds for current tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "fpwRGudV-wK5",
        "outputId": "c4b415c9-c176-44cc-db13-80b1c6ce6379"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3]])"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# You can also use \":\" to select \"all\" of a target dimension\n",
        "x[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "aB9JJ4mt-wK5",
        "outputId": "e5395f42-c7c3-43fb-ce13-9b22f1c0ad5b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2, 5, 8]])"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get all values across the 0th and 1st dimensions, but only the 2nd index of the 2nd dimension\n",
        "x[:, :, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "dPiaN8Cq-wK5",
        "outputId": "68a0f363-5c13-47c5-fc32-a19e29e7894b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([5])"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get all values across the 0th dimension, but only the 1 index value of 1st and 2nd dimension\n",
        "x[:, 1, 1] # retrieves all elements from 0th dimension, grabs the element at index 1 in 1st dimension, grabs the element at index 1 in 2nd dimension\n",
        "\n",
        "# Note that this is very similar to x[0][1][1] except we have an extra dimension [ ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "SKJC3omV-wK5",
        "outputId": "eaea4ca2-b9d2-4b6a-d0ad-f9f264939166"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([5])"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get all values across the 0th dimension, but only the 1 index value of 1st and 2nd dimension\n",
        "x[:, 1, 1] # retrieves all elements from 0th dimension, grabs the element at index 1 in 1st dimension, grabs the element at index 1 in 2nd dimension\n",
        "\n",
        "# Note that this is very similar to x[0][1][1] except we have an extra dimension [ ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "wY86fnJ--wK6",
        "outputId": "c2751003-926e-4e7e-d12c-cc1e5376a038"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get index 0 of 0th and 1st dimension and all values of 2nd dimension\n",
        "x[0, 0, :] # equivalent to x[0][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6O1lXi9E-wK6"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "4ZKVZR6N-wK6",
        "outputId": "c137d7e1-7c8f-419e-f0dd-3581413c1214"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([9])\n",
            "tensor([[3, 6, 9]])\n"
          ]
        }
      ],
      "source": [
        "# Index on x to return 9\n",
        "print(x[:, 2, 2])\n",
        "\n",
        "# Index on x to return 3, 6, 9\n",
        "print(x[:, :, 2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62OWhAJ4-wK6"
      },
      "source": [
        "## PyTorch Tensors & NumPy\n",
        "\n",
        "NumPy is a popular scientific Python numerical computing library.\n",
        "\n",
        "And because of this, PyTorch has functionality to interact with it.\n",
        "\n",
        "* NumPy Data -> PyTorch tensor: `torch.from_numpy(ndarray)`\n",
        "* Pytorch tensor -> NumPy Data: `torch.Tensor.numpy()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "cSfz5D0R-wK6",
        "outputId": "1ff51f88-9949-4db2-81ce-c38ef704c0c3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([1., 2., 3., 4., 5., 6., 7.]), tensor([1., 2., 3., 4., 5., 6., 7.]))"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# NumPy array to tensor\n",
        "\n",
        "array = np.arange(1.0, 8.0)\n",
        "tensor = torch.from_numpy(array).type(torch.float32)\n",
        "array, tensor # warning: NumPy's default datatype is float64, while PyTorch's default datatype is float32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "LiDF_TJN-wK6",
        "outputId": "d3fb9cd7-88bd-4b2b-9fe2-34465f600389"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([2., 3., 4., 5., 6., 7., 8.]), tensor([1., 2., 3., 4., 5., 6., 7.]))"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Change the value of array. what will this do to `tensor`?\n",
        "\n",
        "array = array + 1\n",
        "array, tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "jdF8Ik5s-wK6",
        "outputId": "ca0e9e60-862b-4acb-e0f3-cbff2e447a6e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Tensor to NumPy array\n",
        "\n",
        "tensor = torch.ones(7)\n",
        "numpy_tensor = tensor.numpy() # Recall the warning above! It's better to convert to float64 here\n",
        "tensor, numpy_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "a6O0_PnQ-wK6",
        "outputId": "5f5d285f-b294-416e-ebce-907379a9d66d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Change the tensor, what happens to `numpy_tensor`?\n",
        "tensor = tensor + 1\n",
        "tensor, numpy_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "om16MJQp-wK6"
      },
      "source": [
        "## Reproducability (trying to take random out of random)\n",
        "\n",
        "### In short how a neural network learns:\n",
        "\n",
        "`start with random numbers -> tensor operations -> update random numbers to try and make them better representations of the data -> again (repeat)`\n",
        "\n",
        "To reduce the randomness in neural networks and Pytorch, we then use the concept of a **random seed**.\n",
        "\n",
        "Essentially what the random seed does is set the initial random number generator to a specific state, so that if you run the same code multiple times, it will produce the same random numbers.\n",
        "\n",
        "### Resource\n",
        "https://pytorch.org/docs/stable/notes/randomness.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "0TErAT-6-wK6",
        "outputId": "c13579a8-e427-49c1-eb62-cf47aa0c6681"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.5551, 0.9699, 0.7323],\n",
              "        [0.7531, 0.6240, 0.0389],\n",
              "        [0.6641, 0.7219, 0.1748]])"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.rand(3, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "8spN6Lty-wK6",
        "outputId": "252e3e1c-02dc-4b1b-b843-11b4122d24d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.9904, 0.2649, 0.0933, 0.2652],\n",
            "        [0.1414, 0.6662, 0.9613, 0.7012],\n",
            "        [0.9322, 0.0388, 0.1791, 0.5544]])\n",
            "tensor([[0.0441, 0.5297, 0.9194, 0.4380],\n",
            "        [0.1000, 0.7825, 0.6678, 0.1498],\n",
            "        [0.6538, 0.3127, 0.9382, 0.3729]])\n",
            "tensor([[False, False, False, False],\n",
            "        [False, False, False, False],\n",
            "        [False, False, False, False]])\n"
          ]
        }
      ],
      "source": [
        "# Create two random tensors\n",
        "random_tensor_A = torch.rand(3, 4)\n",
        "random_tensor_B = torch.rand(3, 4)\n",
        "\n",
        "print(random_tensor_A)\n",
        "print(random_tensor_B)\n",
        "print(random_tensor_A == random_tensor_B) # You likely won't ever get \"True\" here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "OvNelE68-wK6",
        "outputId": "b2250980-f763-4aaa-a27b-0b59affa52f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "tensor([[True, True, True, True],\n",
            "        [True, True, True, True],\n",
            "        [True, True, True, True]])\n"
          ]
        }
      ],
      "source": [
        "# Let's make some random but reproducible tensors\n",
        "\n",
        "# Set the random seed\n",
        "RANDOM_SEED = 42 # An arbitrary number\n",
        "torch.manual_seed(RANDOM_SEED) # torch.manual_seed() generally only works for one block of code\n",
        "\n",
        "random_tensor_C = torch.rand(3, 4)\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED) # Without this line, tensor C != tensor D\n",
        "\n",
        "random_tensor_D = torch.rand(3, 4)\n",
        "\n",
        "print(random_tensor_C)\n",
        "print(random_tensor_D)\n",
        "print(random_tensor_C == random_tensor_D)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoiInSKW-wK6"
      },
      "source": [
        "## Running tensors and PyTorch objects on the GPUs (and making faster computations)\n",
        "\n",
        "Computing on tensors generally happens much faster on GPUs (graphics processing units, typically from NVIDIA) than CPUs (computer processing units).\n",
        "\n",
        "MPS stands for \"Metal Performance Shader\" which is Apple's GPU (M1, M1 Pro, M2 etc).\n",
        "\n",
        "It is advised to perform training on the fastest piece of hardware you have available, which will generally be: NVIDIA GPU (\"cuda\") > MPS device (\"mps\") > CPU (\"cpu\")."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZWhzQFo-wK6"
      },
      "source": [
        "### 1. Getting a GPU\n",
        "\n",
        "\n",
        "| **Method** | **Difficulty to setup** | **Pros** | **Cons** | **How to setup** |\n",
        "| ----- | ----- | ----- | ----- | ----- |\n",
        "| Google Colab | Easy | Free to use, almost zero setup required, can share work with others as easy as a link | Doesn't save your data outputs, limited compute, subject to timeouts | [Follow the Google Colab Guide](https://colab.research.google.com/notebooks/gpu.ipynb) |\n",
        "| Use your own | Medium | Run everything locally on your own machine | GPUs aren't free, require upfront cost | Follow the [PyTorch installation guidelines](https://pytorch.org/get-started/locally/) |\n",
        "| Cloud computing (AWS, GCP, Azure) | Medium-Hard | Small upfront cost, access to almost infinite compute | Can get expensive if running continually, takes some time to setup right | Follow the [PyTorch installation guidelines](https://pytorch.org/get-started/cloud-partners/) |\n",
        "\n",
        "There are more options for using GPUs but the above three will suffice for now.\n",
        "\n",
        "Personally, I use a combination of Google Colab and my own personal computer for small scale experiments (and creating this course) and go to cloud resources when I need more compute power.\n",
        "\n",
        "> **Resource:** If you're looking to purchase a GPU of your own but not sure what to get, [Tim Dettmers has an excellent guide](https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/).\n",
        "\n",
        "To check if you've got access to a Nvidia GPU, you can run `!nvidia-smi` where the `!` (also called bang) means \"run this on the command line\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ds_57sXZ-wK6"
      },
      "source": [
        "### 2. Check for GPU with PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "H7TT784F-wK6",
        "outputId": "b551d3ff-7f78-4663-9022-9f7a8ab90ed0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: mps\n"
          ]
        }
      ],
      "source": [
        "# Setup Device-Agnostic Code\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\" # NVIDIA GPU\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = \"mps\" # Apple GPU\n",
        "else:\n",
        "    device = \"cpu\" # Defaults to CPU if NVIDIA GPU/Apple GPU aren't available\n",
        "\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "tjukfTur-wK6",
        "outputId": "d4f68e39-cc61-4a80-f88c-8e9cf2d3e960"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Count number of devices\n",
        "torch.mps.device_count()\n",
        "# torch.cuda.device_count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnpxnHyc-wK6"
      },
      "source": [
        "### 3. Putting tensors (and models) on the GPU\n",
        "The reason we want our tensors/models on the GPU is because using a GPU results in faster computations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "hBDD8kQI-wK6",
        "outputId": "28c36378-5abb-4085-8a89-fac78f5e4f54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1, 2, 3]) cpu\n"
          ]
        }
      ],
      "source": [
        "# Create a tensor (default on the CPU)\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "\n",
        "# Tensor not on GPU\n",
        "print(tensor, tensor.device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "EP1zSG9x-wK7",
        "outputId": "30e1a6fe-c914-43e9-af9a-5b803a9b7a66"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], device='mps:0')"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Move tensor to GPU if available\n",
        "tensor_on_gpu = tensor.to(device)\n",
        "tensor_on_gpu # mps:0 refers to index 0 of MPS device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-4vQLKK-wK7"
      },
      "source": [
        "### 4. Moving tensors back to CPU\n",
        "This is important because there are some operations that are only supported on the CPU, such as NumPy operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "KI54WCpA-wK7",
        "outputId": "42735b72-b415-432b-a84a-358acbaa8b32"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# If tensor is on GPU, can't transform it to NumPy\n",
        "#tensor_on_gpu.numpy()  # Raises an error\n",
        "\n",
        "# To fix the GPU tensor with NumPy issue, we can first set it to the CPU\n",
        "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
        "tensor_back_on_cpu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": false,
        "id": "dFZC_OR0-wK7",
        "outputId": "019495e9-c06e-47fa-cbbd-732ffa48b1c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], device='mps:0')"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_on_gpu"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}