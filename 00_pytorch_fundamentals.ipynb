{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JunHL96/PyTorch/blob/main/00_pytorch_fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA2szA5NyQM1"
      },
      "source": [
        "## 00. Pytorch Fundamentals\n",
        "\n",
        "Resource notebook: https://www.learnpytorch.io/00_pytorch_fundamentals/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1eVzdLQQyQM2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZs9jj6jyQM2"
      },
      "source": [
        "### If Apple Silicon User:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUuajqLEyQM2"
      },
      "outputs": [],
      "source": [
        "# Setup device-agnostic code\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\" # NVIDIA GPU\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = \"mps\" # Apple GPU\n",
        "else:\n",
        "    device = \"cpu\" # Defaults to CPU if NVIDIA GPU/Apple GPU aren't available\n",
        "\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3jUZzWfyQM3"
      },
      "source": [
        "## Introduction to Tensors\n",
        "\n",
        "### What are tensors?\n",
        "\n",
        "A tensor is a multi-dimensional matrix containing elements of a single data type.\n",
        "\n",
        "### Creating tensors\n",
        "\n",
        "PyTorch tensors are created using 'torch.tensor()' = https://pytorch.org/docs/stable/tensors.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFpvr4N3yQM3"
      },
      "outputs": [],
      "source": [
        "# scalar\n",
        "scalar = torch.tensor(7, device = device)\n",
        "scalar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2r1cBpkyQM3"
      },
      "outputs": [],
      "source": [
        "scalar.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NFTcyW0yQM3"
      },
      "outputs": [],
      "source": [
        "# Get tensor back as Python int\n",
        "scalar.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u64AjAQ5yQM3"
      },
      "outputs": [],
      "source": [
        "# Vector (magnitude, direction)\n",
        "vector = torch.tensor([7, 7], device = device)\n",
        "vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X4vIqSLnyQM3"
      },
      "outputs": [],
      "source": [
        "vector.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_TP7UHcyQM3"
      },
      "outputs": [],
      "source": [
        "vector.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w326ArDRyQM3"
      },
      "source": [
        "<details>\n",
        "\n",
        "### `.shape`\n",
        "- **Returns the dimensions of the tensor (or array)** as a tuple.\n",
        "- Each element of the tuple (an ordered, immutable collection of items) represents the size of the tensor in that dimension.\n",
        "\n",
        "Example:\n",
        "```python\n",
        "vector = torch.tensor([7, 7])\n",
        "print(vector.shape)  # Output: torch.Size([2])\n",
        "```\n",
        "\n",
        "### `.ndim`\n",
        "- **Returns the number of dimensions (rank) of the tensor.**\n",
        "- this is an integer value representing how many dimensions the tensor has\n",
        "\n",
        "Example:\n",
        "```python\n",
        "vector = torch.tensor([7, 7])\n",
        "print(vector.ndim)  # Output: 1\n",
        "```\n",
        "\n",
        "### Explanation:\n",
        "- `vector = torch.tensor([7, 7])` creates a 1D tensor (vector) with 2 elements.\n",
        "- `.shape` gives `(2)` because the vector has 2 elements in one dimension.\n",
        "- `.ndim` gives `1` because the tensor is 1-dimensional.\n",
        "\n",
        "\n",
        "| Attribute  | Description                               | Example Output            |\n",
        "|------------|-------------------------------------------|---------------------------|\n",
        "| `.shape`   | Tuple representing the size of each dimension | `torch.Size([2])`   |\n",
        "| `.ndim`    | Integer representing the number of dimensions | `1`                       |\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8wclMB2yQM3"
      },
      "source": [
        "## Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8k1BHeAyQM3"
      },
      "outputs": [],
      "source": [
        "# MATRIX\n",
        "MATRIX = torch.tensor([[7, 8],\n",
        "                      [9, 10]], device = device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "llc07RI8yQM3"
      },
      "outputs": [],
      "source": [
        "MATRIX.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GcEb_5VyQM3"
      },
      "outputs": [],
      "source": [
        "MATRIX[0] # index on 0th axis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qsM-ZPOyQM4"
      },
      "outputs": [],
      "source": [
        "MATRIX[1] # index on 1st axis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M725NoiryQM4"
      },
      "outputs": [],
      "source": [
        "MATRIX.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLRvcVwOyQM4"
      },
      "source": [
        "## Tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wE6rPuNyQM4"
      },
      "outputs": [],
      "source": [
        "# TENSOR\n",
        "TENSOR = torch.tensor([[[1, 2, 3],\n",
        "                        [3, 6, 9],\n",
        "                        [2, 4, 5]]], device = device)\n",
        "TENSOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPPOXEGpyQM4"
      },
      "outputs": [],
      "source": [
        "TENSOR.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtZ7nvrTyQM4"
      },
      "outputs": [],
      "source": [
        "TENSOR.shape # the result is torch.Size([1, 3, 3]), meaning we have one dimension of 3x3 tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtwYAMKOyQM4"
      },
      "source": [
        "### Image Representation\n",
        "https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-pytorch-different-tensor-dimensions.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4fjmFzVyQM4"
      },
      "outputs": [],
      "source": [
        "TENSOR[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OZ1cGZsyQM4"
      },
      "source": [
        "## Random Tensors\n",
        "\n",
        "### Why Random Tensors?\n",
        "Random tensors are important b/c the way many neural networks learn is that they start with tensors full of random numbers and then adjust those random numbers to better represent the data.\n",
        "\n",
        "`Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers`\n",
        "\n",
        "### Documentation of torch.rand\n",
        "https://pytorch.org/docs/stable/generated/torch.rand.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UX3pEjzlyQM4"
      },
      "outputs": [],
      "source": [
        "# Create a random tensor of size (3, 4)\n",
        "\n",
        "random_tensor = torch.rand(3, 4, device=device)\n",
        "#random_tensor = torch.rand(5, 10, 10, device=mps)\n",
        "random_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLPPB2zGyQM4"
      },
      "outputs": [],
      "source": [
        "random_tensor.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtmT1F-TyQM4"
      },
      "outputs": [],
      "source": [
        "# Create a random tensor with similar shape to an image tensor\n",
        "random_image_size_tensor = torch.rand(size=(224, 224, 3), device=device) # height, width, color channels (R, G, B)\n",
        "random_image_size_tensor.shape, random_image_size_tensor.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ba5JyP-0yQM4"
      },
      "source": [
        "### Image Representation\n",
        "https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-tensor-shape-example-of-image.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kz5ABs_vyQM4"
      },
      "source": [
        "### Zeroes and Ones Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybpaKbTIyQM4"
      },
      "outputs": [],
      "source": [
        "# Create a tensor of all zeros\n",
        "zeros = torch.zeros(size=(3, 4))\n",
        "zeros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNh-dWQuyQM4"
      },
      "outputs": [],
      "source": [
        "# Create a tensor of all ones\n",
        "ones = torch.ones(size=(3, 4))\n",
        "ones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCw6lN8byQM4"
      },
      "outputs": [],
      "source": [
        "random_tensor.dtype # check data type of tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYEZkJQ6yQM5"
      },
      "source": [
        "## Creating a range of tensors and tensors-like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03D3hqxvyQM5"
      },
      "outputs": [],
      "source": [
        "# Use torch.arange()\n",
        "one_to_ten = torch.arange(start=1, end=11, step = 1, device=device)\n",
        "one_to_ten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rBcgwBWyQM5"
      },
      "outputs": [],
      "source": [
        "# Creating tensors-like\n",
        "ten_zeros = torch.zeros_like(input=one_to_ten) # the zeros_like function creates a new tensor with same shape as the input\n",
        "ten_zeros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVyGDvt4yQM5"
      },
      "source": [
        "## Tensor Datatypes\n",
        "\n",
        "**Note:** Tensor datatypes is one of the 3 big potential errors you'll run into with PyTorch & Deep Learning:\n",
        "1. Tensors are not the right datatype\n",
        "2. Tensors are not the right shape\n",
        "3. Tensors are not on the right device (such as cpu, cuda, mps, etc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmWEgM4iyQM5"
      },
      "outputs": [],
      "source": [
        "# Float 32 tensor\n",
        "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                               dtype=None,  # what datatype is the tensor (e.g. float32, float16)\n",
        "                               device=device, # What device is your tensor on\n",
        "                               requires_grad=False) # whether or not to track gradients with this tensors operation\n",
        "float_32_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8pvZg4-yQM5"
      },
      "outputs": [],
      "source": [
        "float_32_tensor.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiCYfammyQM8"
      },
      "outputs": [],
      "source": [
        "float_16_tensor = float_32_tensor.type(torch.float16)\n",
        "float_16_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flZpK_AuyQM8"
      },
      "outputs": [],
      "source": [
        "int_32_tensor = torch.tensor([3, 6, 9], dtype=torch.int32, device=device)\n",
        "int_32_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6VWJWXDyQM8"
      },
      "source": [
        "### Getting Information from Tensors\n",
        "\n",
        "1. Tensors are not the right datatype - to get detatype from a tensor, can use `tensor.dtype`\n",
        "2. Tensors are not the right shape - to get shape from a tensor, can use `tensor.shape`\n",
        "3. Tensors are not on the right device - to get device from a tensor, can use `tensor.device`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQ7-LcOVyQM8"
      },
      "outputs": [],
      "source": [
        "# Create a tensor to get information from\n",
        "test_tensor1 = torch.rand(3, 4, dtype=torch.float64)\n",
        "test_tensor2 = torch.rand(3, 4, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QdG1X2-FyQM8"
      },
      "outputs": [],
      "source": [
        "# Find out information\n",
        "print(test_tensor1)\n",
        "print(f\"Datatype of tensor1: {test_tensor1.dtype}\")\n",
        "print(f\"Datatype of tensor2: {test_tensor2.dtype}\")\n",
        "print(f\"Shape of tensor: {test_tensor1.shape}\")\n",
        "print(f\"Device tensor1 is on: {test_tensor1.device}\")\n",
        "print(f\"Device tensor2 is on: {test_tensor2.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-XwHxW8yQM8"
      },
      "source": [
        "### Manipulating Tensors (Tensor Operations)\n",
        "\n",
        "Tensor operations include:\n",
        "* Addition\n",
        "* Subtraction\n",
        "* Multiplication (element-wise)\n",
        "* Division\n",
        "* Matrix Multiplication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AInfZv6-yQM8"
      },
      "outputs": [],
      "source": [
        "# Create a tensor\n",
        "tensor = torch.tensor([1, 2, 3], device=device)\n",
        "tensor + 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HuxuJMChyQM9"
      },
      "outputs": [],
      "source": [
        "# Multiply tensor by 10\n",
        "tensor * 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAffEZ2XyQM9"
      },
      "outputs": [],
      "source": [
        "# Subtract by 10\n",
        "tensor - 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l35utv4eyQM9"
      },
      "outputs": [],
      "source": [
        "# Try out Pytorch in-built functions\n",
        "torch.mul(tensor, 10) # Generally, you want to use Python functions instead"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRtc4HV6yQM9"
      },
      "outputs": [],
      "source": [
        "torch.add(tensor, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nokkWY6TyQM9"
      },
      "source": [
        "### Matrix Multiplication\n",
        "\n",
        "Two main ways of performing multiplication in neural networks and deep learning:\n",
        "\n",
        "1. Element-wise multiplication\n",
        "2. Matrix multiplication (dot-product)\n",
        "\n",
        "The main two rules for matrix multiplication to remember are:\n",
        "\n",
        "* The inner dimensions must match: \\\\\n",
        "(3, 2) @ (3, 2) won't work \\\\\n",
        "(2, 3) @ (3, 2) will work \\\\\n",
        "(3, 2) @ (2, 3) will work \\\\\n",
        "* The resulting matrix has the shape of the outer dimensions: \\\\\n",
        "(2, 3) @ (3, 2) -> (2, 2) \\\\\n",
        "(3, 2) @ (2, 3) -> (3, 3)\n",
        "\n",
        "```\n",
        "Note: \"@\" in Python is the symbol for matrix multiplication.\n",
        "```\n",
        "```\n",
        "Resource: You can see all of the rules for matrix multiplication using torch.matmul() in the PyTorch documentation.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmilmI_8yQM9"
      },
      "outputs": [],
      "source": [
        "# Element-wise multiplication\n",
        "print(tensor, \"*\", * tensor)\n",
        "print(f\"Equals: {tensor * tensor}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6m5Y0ot4yQM9"
      },
      "outputs": [],
      "source": [
        "# Matrix Multiplication\n",
        "\n",
        "tensor = tensor.float() # currently, MPS device only supports float32\n",
        "torch.matmul(tensor, tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlWMMKKbyQM9"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "value = 0\n",
        "for i in range(len(tensor)):\n",
        "    value += tensor[i] * tensor[i]\n",
        "print(value)\n",
        "# Matrix multiplication by hand\n",
        "# Don't use for loops in PyTorch b/c they are computationally expensive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9uvMtT1yQM9"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "torch.matmul(tensor, tensor)\n",
        "\n",
        "# we see that the in-built function is much more optimized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeNh4Gx0yQM9"
      },
      "outputs": [],
      "source": [
        "torch.matmul(torch.rand(3, 2, device=device), torch.rand(2, 3, device=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzZhgKzmyQM9"
      },
      "outputs": [],
      "source": [
        "torch.matmul(torch.rand(2, 10, device=device), torch.rand(10, 3, device=device))\n",
        "\n",
        "# remember: resulting matrix has the shape of the outer dimensions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31QXGYIuyQM9"
      },
      "source": [
        "### One of the most common errors in Deep Learning: Shape Errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aVyTrUGFyQM9"
      },
      "outputs": [],
      "source": [
        "# Shapes for matrix multiplication\n",
        "tensor_A = torch.tensor([[1, 2],\n",
        "                         [3, 4],\n",
        "                         [5, 6]])\n",
        "\n",
        "tensor_B = torch.tensor([[7, 10],\n",
        "                         [8, 11],\n",
        "                         [9, 12]])\n",
        "\n",
        "\n",
        "# torch.mm(tensor_A, tensor_B) # torch.mm is the same as torch.matmul (alias)\n",
        "#torch.matmul(tensor_A, tensor_B) # uncomment this to get an error because shapes are incompatible"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5FEai-9yQM9"
      },
      "outputs": [],
      "source": [
        "# Check tensor sizes to make sure they are compatible for matrix multiplication\n",
        "tensor_A.shape, tensor_B.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIBGMiIkyQM9"
      },
      "source": [
        "To fix our tensor shape issues, we can manipulate the shape of one of our tensors using a transpose.\n",
        "\n",
        "A **transpose** switches the axes or dimensions of a given tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJtIa1GhyQM9"
      },
      "outputs": [],
      "source": [
        "tensor_B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmD14f1dyQM-"
      },
      "outputs": [],
      "source": [
        "tensor_B.T, tensor_B.T.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2zssMLOyQM-"
      },
      "outputs": [],
      "source": [
        "# transpose switches the dimensions from 3x2 to 2x3\n",
        "tensor_B.T, tensor_B.T.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amI6EalWyQM-"
      },
      "outputs": [],
      "source": [
        "# The matrix multiplication operation works when tensor_B is transposed\n",
        "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\\n\")\n",
        "print(f\"New shapes: tensor_A = {tensor_A.shape} (same shape as above), tensor_B.T = {tensor_B.T.shape}\\n\")\n",
        "print(f\"Multiplying: {tensor_A.shape} @ {tensor_B.T.shape} <- inner dimensions must match\\n\")\n",
        "print(\"Output:\")\n",
        "output = torch.matmul(tensor_A, tensor_B.T)\n",
        "print(output)\n",
        "print(f\"\\nOutput shape: {output.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPazkKYSyQM-"
      },
      "source": [
        "## Finding the min, max, mean, sum, etc (tensor aggregation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fvYQZ2HyQM-"
      },
      "outputs": [],
      "source": [
        "# Create a tensor\n",
        "x = torch.arange(1, 100, 10) # torch.arange(start, end, step)\n",
        "x, x.dtype\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7XVepiS8yQM-"
      },
      "outputs": [],
      "source": [
        "# Find the min, note that both torch.sum(x) and x.sum() are functionally equivalent\n",
        "torch.min(x), x.min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRWKR_GIyQM-"
      },
      "outputs": [],
      "source": [
        "# Find the max\n",
        "torch.max(x), x.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CB5HKyOyQM-"
      },
      "outputs": [],
      "source": [
        "# Find the mean\n",
        "#torch.mean(x), x.mean() # This will result in an error because x is not a float tensor\n",
        "\n",
        "# the torch.mean() function requires a tensor of float32 dtype to work properly\n",
        "torch.mean(x.type(torch.float32)), x.type(torch.float32).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vz0_vVhWyQM-"
      },
      "outputs": [],
      "source": [
        "# Find the sum\n",
        "torch.sum(x), x.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwH_ilD9yQM-"
      },
      "source": [
        "## Finding the positional min and max"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWjaDl0ByQM-"
      },
      "outputs": [],
      "source": [
        "# Find the position in tensor that has the minimum value with argmin()\n",
        "x.argmin() # This returns index position of target tensor where the minimum value occurs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z1GdO4SfyQM-"
      },
      "outputs": [],
      "source": [
        "x[0] # This returns the actual minimum value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Qs6Ft4lyQM-"
      },
      "outputs": [],
      "source": [
        "# Find the position in tensor that has the maximum value with argmax()\n",
        "x. argmax()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E10pEJAnyQM-"
      },
      "outputs": [],
      "source": [
        "x[9] # This returns the actual maximum value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSOGM-_iyQM-"
      },
      "source": [
        "## Reshaping, stacking, squeezing and unsqueezing tensors\n",
        "\n",
        "* Reshaping - reshapes an input tensor into a defined shape\n",
        "* View - return a view of an input tensor of a certain shape but keep the same memory as the original tensor\n",
        "* Stacking - combine multiple tensors on top of each other (vstack) or side by side (hstack)\n",
        "* Squeeze - removes all `1` dimensions from a tensor\n",
        "* Unsqueeze - adds a `1` dimension to a target tensor\n",
        "* Permute - return a view of the input with dimensions permuted (swapped) in a certain way"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBEHlihvyQM-"
      },
      "outputs": [],
      "source": [
        "# Create a tensor\n",
        "x = torch.arange(1., 10.)\n",
        "x, x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IPrqwTjyQM-"
      },
      "outputs": [],
      "source": [
        "# Add an extra dimension to the tensor\n",
        "\n",
        "# x.reshape(dim1, dim2, ..., dimN) # Dimension must have the same number of elements as the original tensor, same number as what torch.Size gives\n",
        "#x_reshaped = x.reshape(1, 7) # Error occurs because reshaping to (1, 7) is invalid as the total number of elements must remain the same.\n",
        "#x_reshaped = x.reshape(2, 9) # Error occurs because this would require 18 elements, but we only have 9.\n",
        "x_reshaped = x.reshape(9, 1)\n",
        "x_reshaped, x_reshaped.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STkq_6hRyQM-"
      },
      "outputs": [],
      "source": [
        "# Change the view\n",
        "z = x.view(1, 9)\n",
        "z, z.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "au_J1XzvyQM_"
      },
      "outputs": [],
      "source": [
        "# Changing z changes x (because a view of a tensor shares the same memory as the original tensor)\n",
        "z[:, 0] = 5 # This changes the first element of z to 5\n",
        "z, x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYBC_wjkyQM_"
      },
      "outputs": [],
      "source": [
        "# Stack tensors on top of each other\n",
        "\n",
        "# Stack tensors on top of each other along the first dimension (rows), creating a 2D tensor.\n",
        "x_stacked = torch.stack([x, x, x, x], dim=0)\n",
        "\n",
        "# Stack tensors side by side along the second dimension (columns), creating a 2D tensor.\n",
        "#x_stacked = torch.stack([x, x, x, x], dim=1)\n",
        "\n",
        "# Attempt to stack tensors along the third dimension, but this will result in an error for 1D tensors.\n",
        "#x_stacked = torch.stack([x, x, x, x], dim=2)\n",
        "\n",
        "x_stacked\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9wvKvU0yQM_"
      },
      "outputs": [],
      "source": [
        "# torch.squeeze(input, dim=None) - removes all single dimensions from a target tensor\n",
        "print(f\"Previous tensor: {x_reshaped}\")\n",
        "print(f\"Previous shape: {x_reshaped.shape}\")\n",
        "\n",
        "# Remove extra dimensions from x_reshaped\n",
        "x_squeezed = x_reshaped.squeeze()\n",
        "print(f\"\\nNew tensor: {x_squeezed}\")\n",
        "print(f\"New shape: {x_squeezed.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5tCyMBFyQM_"
      },
      "outputs": [],
      "source": [
        "# torch.unsqueeze(input, dim) - adds a single dimension to a target tensor at a specific dim\n",
        "print(f\"Previous target: {x_squeezed}\")\n",
        "print(f\"Previous shape: {x_squeezed.shape}\")\n",
        "\n",
        "# Add an extra dimension with unsqueeze\n",
        "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
        "print(f\"\\nNew tensor: {x_unsqueezed}\")\n",
        "print(f\"New shape: {x_unsqueezed.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlsqhh2oyQM_"
      },
      "outputs": [],
      "source": [
        "# torch.unsqueeze(input, dim) - adds a single dimension to a target tensor at a specific dim\n",
        "print(f\"Previous target: {x_squeezed}\")\n",
        "print(f\"Previous shape: {x_squeezed.shape}\")\n",
        "\n",
        "# Add an extra dimension with unsqueeze\n",
        "x_unsqueezed = x_squeezed.unsqueeze(dim=1)\n",
        "print(f\"\\nNew tensor: \\n{x_unsqueezed}\")\n",
        "print(f\"New shape: {x_unsqueezed.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8hwyZLYyQM_"
      },
      "outputs": [],
      "source": [
        "# torch.permute - rearranges the dimensions of a target tensor of a specified order\n",
        "x_original = torch.rand(size=(224, 224, 3)) # [height, width, color_channels]\n",
        "\n",
        "# Permute the original tensor to rearrange the axis order\n",
        "x_permuted = x_original.permute(2, 0, 1) # shifts axis 0->1, 1->2, 2->0\n",
        "\n",
        "print(f\"Previous shape: {x_original.shape}\")\n",
        "print(f\"New shape: {x_permuted.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qlkv1q_yQM_"
      },
      "source": [
        "Remember the purpose of reshaping, stacking, squeezing, and unsqueezing tensors: these help us fix shape and dimension issues with tensors, which is the most common error in Deep Learning and Neural Networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLNkv4MfyQM_"
      },
      "source": [
        "## Indexing (selecting data from tensors)\n",
        "\n",
        "Indexing with PyTorch is similar to indexing with NumPy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apd6k7uRyQM_"
      },
      "outputs": [],
      "source": [
        "# Create a tensor\n",
        "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
        "x, x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvFuJ8KjyQM_"
      },
      "outputs": [],
      "source": [
        "# Let's index on our new tensor\n",
        "x[0], x[0].shape # Indexing on the first dimension (batch dimension)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IL4nzAbRyQM_"
      },
      "outputs": [],
      "source": [
        "# Let's index on the middle bracket (dim=1)\n",
        "x[0][0], x[0][0].shape # Indexing on the second dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gL6zFzv6yQM_"
      },
      "outputs": [],
      "source": [
        "# Let's index on the most inner bracket (last dimension)\n",
        "x[0][0][0], x[0][0][0].shape # Indexing on the third dimension\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "suUAwfHTyQM_"
      },
      "outputs": [],
      "source": [
        "# Play around with the indexing!\n",
        "x[0][2][2], x[0][2][2].shape # note that for our current tensor, x[1][0][0] will give us an error b/c the index is out of bounds for current tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6DKJe65yQM_"
      },
      "outputs": [],
      "source": [
        "# You can also use \":\" to select \"all\" of a target dimension\n",
        "x[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hXUvlRVyQM_"
      },
      "outputs": [],
      "source": [
        "# Get all values across the 0th and 1st dimensions, but only the 2nd index of the 2nd dimension\n",
        "x[:, :, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLuofKEKyQM_"
      },
      "outputs": [],
      "source": [
        "# Get all values across the 0th dimension, but only the 1 index value of 1st and 2nd dimension\n",
        "x[:, 1, 1] # retrieves all elements from 0th dimension, grabs the element at index 1 in 1st dimension, grabs the element at index 1 in 2nd dimension\n",
        "\n",
        "# Note that this is very similar to x[0][1][1] except we have an extra dimension [ ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EK6KsnhDyQM_"
      },
      "outputs": [],
      "source": [
        "# Get all values across the 0th dimension, but only the 1 index value of 1st and 2nd dimension\n",
        "x[:, 1, 1] # retrieves all elements from 0th dimension, grabs the element at index 1 in 1st dimension, grabs the element at index 1 in 2nd dimension\n",
        "\n",
        "# Note that this is very similar to x[0][1][1] except we have an extra dimension [ ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJLbzv-MyQNA"
      },
      "outputs": [],
      "source": [
        "# Get index 0 of 0th and 1st dimension and all values of 2nd dimension\n",
        "x[0, 0, :] # equivalent to x[0][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdwQ3SFZyQNA"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}