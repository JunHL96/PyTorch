{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JunHL96/PyTorch/blob/main/00_pytorch_fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHf3v7-7w67Z"
      },
      "source": [
        "## 00. Pytorch Fundamentals\n",
        "\n",
        "Resource notebook: https://www.learnpytorch.io/00_pytorch_fundamentals/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VDFwEGrEw67Z",
        "outputId": "1e8b75f7-c699-40cc-a3a0-0839f03e8d5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4.1+cu121\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRJE8eylw67a"
      },
      "source": [
        "### If Apple Silicon User:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qfMfsNEew67a",
        "outputId": "4a6ab567-dd04-48c6-e39a-9010c1ec06ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "# Setup device-agnostic code\n",
        "if torch.cuda.is_available():\n",
        "    device = \"cuda\" # NVIDIA GPU\n",
        "elif torch.backends.mps.is_available():\n",
        "    device = \"mps\" # Apple GPU\n",
        "else:\n",
        "    device = \"cpu\" # Defaults to CPU if NVIDIA GPU/Apple GPU aren't available\n",
        "\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOm9o5ngw67a"
      },
      "source": [
        "## Introduction to Tensors\n",
        "\n",
        "### What are tensors?\n",
        "\n",
        "A tensor is a multi-dimensional matrix containing elements of a single data type.\n",
        "\n",
        "### Creating tensors\n",
        "\n",
        "PyTorch tensors are created using 'torch.tensor()' = https://pytorch.org/docs/stable/tensors.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "luCU-d9Lw67b",
        "outputId": "91e9cf0b-148c-49d5-9051-18d27810c3f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# scalar\n",
        "scalar = torch.tensor(7, device = device)\n",
        "scalar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "k1ORdztGw67b",
        "outputId": "d8464294-f6a5-462c-a99a-1eb335c3c0a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "scalar.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5qmLP-rYw67b",
        "outputId": "b845edc7-bff2-4b69-ff55-4db1cf1c6375",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Get tensor back as Python int\n",
        "scalar.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fKI_JegIw67b",
        "outputId": "2403c01a-213a-43c3-9802-710f03bc3047",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Vector (magnitude, direction)\n",
        "vector = torch.tensor([7, 7], device = device)\n",
        "vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "pdD7FuUdw67b",
        "outputId": "2332705f-1b81-40b9-a915-60a59b68e1a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "vector.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "uWm3O2sew67b",
        "outputId": "d4ab80a1-56c5-4d28-9781-5564af6437fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "vector.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5Ehw8cPw67b"
      },
      "source": [
        "<details>\n",
        "\n",
        "### `.shape`\n",
        "- **Returns the dimensions of the tensor (or array)** as a tuple.\n",
        "- Each element of the tuple (an ordered, immutable collection of items) represents the size of the tensor in that dimension.\n",
        "\n",
        "Example:\n",
        "```python\n",
        "vector = torch.tensor([7, 7])\n",
        "print(vector.shape)  # Output: torch.Size([2])\n",
        "```\n",
        "\n",
        "### `.ndim`\n",
        "- **Returns the number of dimensions (rank) of the tensor.**\n",
        "- this is an integer value representing how many dimensions the tensor has\n",
        "\n",
        "Example:\n",
        "```python\n",
        "vector = torch.tensor([7, 7])\n",
        "print(vector.ndim)  # Output: 1\n",
        "```\n",
        "\n",
        "### Explanation:\n",
        "- `vector = torch.tensor([7, 7])` creates a 1D tensor (vector) with 2 elements.\n",
        "- `.shape` gives `(2)` because the vector has 2 elements in one dimension.\n",
        "- `.ndim` gives `1` because the tensor is 1-dimensional.\n",
        "\n",
        "\n",
        "| Attribute  | Description                               | Example Output            |\n",
        "|------------|-------------------------------------------|---------------------------|\n",
        "| `.shape`   | Tuple representing the size of each dimension | `torch.Size([2])`   |\n",
        "| `.ndim`    | Integer representing the number of dimensions | `1`                       |\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2jwYNvgw67b"
      },
      "source": [
        "## Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2BBHm7-4w67c"
      },
      "outputs": [],
      "source": [
        "# MATRIX\n",
        "MATRIX = torch.tensor([[7, 8],\n",
        "                      [9, 10]], device = device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "uvo6iMcvw67c",
        "outputId": "26e8751d-a20a-4fa0-c6cd-1bb3355f7c09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "MATRIX.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_CX84zrCw67c",
        "outputId": "8d14eb64-f21c-4d9b-e570-8d88ef8d142c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "MATRIX[0] # index on 0th axis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "xTD7mO7Nw67c",
        "outputId": "37321101-9667-494e-b7be-68bf7c76fc5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 9, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "MATRIX[1] # index on 1st axis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "evq2HKp8w67c",
        "outputId": "747be715-2db7-44fe-9025-5b4343dc774a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "MATRIX.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXU6Mtx_w67c"
      },
      "source": [
        "## Tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "cDp50lsEw67c",
        "outputId": "71171e90-9cd1-4508-96af-ec3a2c95c84c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1, 2, 3],\n",
              "         [3, 6, 9],\n",
              "         [2, 4, 5]]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# TENSOR\n",
        "TENSOR = torch.tensor([[[1, 2, 3],\n",
        "                        [3, 6, 9],\n",
        "                        [2, 4, 5]]], device = device)\n",
        "TENSOR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "7-LZCi3Tw67c",
        "outputId": "7ab2397f-028f-45f7-81d4-4532d6918f7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "TENSOR.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mzZF87o8w67c",
        "outputId": "2a14d710-644b-4ded-ca6e-672c85ea18a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "TENSOR.shape # the result is torch.Size([1, 3, 3]), meaning we have one dimension of 3x3 tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s69sWeNpw67c"
      },
      "source": [
        "### Image Representation\n",
        "https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-pytorch-different-tensor-dimensions.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RXPjieZAw67c",
        "outputId": "c3fba063-f1e5-4454-94f4-d32325dcf334",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [3, 6, 9],\n",
              "        [2, 4, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "TENSOR[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJxt3wFqw67d"
      },
      "source": [
        "## Random Tensors\n",
        "\n",
        "### Why Random Tensors?\n",
        "Random tensors are important b/c the way many neural networks learn is that they start with tensors full of random numbers and then adjust those random numbers to better represent the data.\n",
        "\n",
        "`Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers`\n",
        "\n",
        "### Documentation of torch.rand\n",
        "https://pytorch.org/docs/stable/generated/torch.rand.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "6TeJEuAVw67d",
        "outputId": "01f58a89-34cf-44bc-f645-aee08a3ea6ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.9813, 0.4579, 0.5195, 0.9895],\n",
              "        [0.7485, 0.3378, 0.1717, 0.6605],\n",
              "        [0.3102, 0.1634, 0.7430, 0.3854]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Create a random tensor of size (3, 4)\n",
        "\n",
        "random_tensor = torch.rand(3, 4, device=device)\n",
        "#random_tensor = torch.rand(5, 10, 10, device=mps)\n",
        "random_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Gouf6F-4w67d",
        "outputId": "9225c66c-e40e-40f0-e523-3bd0fbdd3367",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "random_tensor.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "svKTBj5nw67d",
        "outputId": "c7df68d9-367f-4b35-8fe2-3379474dcfa3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([224, 224, 3]), 3)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Create a random tensor with similar shape to an image tensor\n",
        "random_image_size_tensor = torch.rand(size=(224, 224, 3), device=device) # height, width, color channels (R, G, B)\n",
        "random_image_size_tensor.shape, random_image_size_tensor.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2asV2SjAw67d"
      },
      "source": [
        "### Image Representation\n",
        "https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-tensor-shape-example-of-image.png"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yoHSbHww67d"
      },
      "source": [
        "### Zeroes and Ones Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "LYVS34zuw67d",
        "outputId": "91994c00-b012-48e6-e3bd-4ede14a3c5be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# Create a tensor of all zeros\n",
        "zeros = torch.zeros(size=(3, 4))\n",
        "zeros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "hQ_xzQJww67d",
        "outputId": "920108b3-a888-4a5d-f880-bd241c763fa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# Create a tensor of all ones\n",
        "ones = torch.ones(size=(3, 4))\n",
        "ones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "jw4NouCsw67d",
        "outputId": "a1c64015-2815-4ce4-becd-dd260bfb8047",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "random_tensor.dtype # check data type of tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABeyS72Bw67d"
      },
      "source": [
        "## Creating a range of tensors and tensors-like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "3FSrNUdMw67d",
        "outputId": "13b1855c-e657-4299-92df-8b4dc86b2f9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# Use torch.arange()\n",
        "one_to_ten = torch.arange(start=1, end=11, step = 1, device=device)\n",
        "one_to_ten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "J06eu4E_w67d",
        "outputId": "264827cd-b726-489d-cb5e-925c7cd52cd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# Creating tensors-like\n",
        "ten_zeros = torch.zeros_like(input=one_to_ten) # the zeros_like function creates a new tensor with same shape as the input\n",
        "ten_zeros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ZJ3HDLSw67e"
      },
      "source": [
        "## Tensor Datatypes\n",
        "\n",
        "**Note:** Tensor datatypes is one of the 3 big potential errors you'll run into with PyTorch & Deep Learning:\n",
        "1. Tensors are not the right datatype\n",
        "2. Tensors are not the right shape\n",
        "3. Tensors are not on the right device (such as cpu, cuda, mps, etc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "JIZEU42mw67e",
        "outputId": "aeed2d5b-66c0-4325-8bd2-2b18052559bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3., 6., 9.])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# Float 32 tensor\n",
        "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                               dtype=None,  # what datatype is the tensor (e.g. float32, float16)\n",
        "                               device=device, # What device is your tensor on\n",
        "                               requires_grad=False) # whether or not to track gradients with this tensors operation\n",
        "float_32_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "tIOQ2Lvzw67e",
        "outputId": "c7d5a3d9-785e-46e0-df05-2a2b90f5459d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "float_32_tensor.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "9S6JY-nAw67i",
        "outputId": "4bbc37c4-261e-4fb8-d209-259138d8f067",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3., 6., 9.], dtype=torch.float16)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "float_16_tensor = float_32_tensor.type(torch.float16)\n",
        "float_16_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "bqUi9Zqkw67i",
        "outputId": "62b72bbd-87bb-4dd4-c1e2-af2c75edfebd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 6, 9], dtype=torch.int32)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "int_32_tensor = torch.tensor([3, 6, 9], dtype=torch.int32, device=device)\n",
        "int_32_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ij-Vag5zw67i"
      },
      "source": [
        "### Getting Information from Tensors\n",
        "\n",
        "1. Tensors are not the right datatype - to get detatype from a tensor, can use `tensor.dtype`\n",
        "2. Tensors are not the right shape - to get shape from a tensor, can use `tensor.shape`\n",
        "3. Tensors are not on the right device - to get device from a tensor, can use `tensor.device`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "RmRlK54cw67i"
      },
      "outputs": [],
      "source": [
        "# Create a tensor to get information from\n",
        "test_tensor1 = torch.rand(3, 4, dtype=torch.float64)\n",
        "test_tensor2 = torch.rand(3, 4, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "VEuKIfViw67j",
        "outputId": "57ce4362-9278-446f-b18e-1a15ad3cb759",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5965, 0.9993, 0.7433, 0.0671],\n",
            "        [0.0504, 0.8295, 0.5015, 0.8153],\n",
            "        [0.4478, 0.8534, 0.2018, 0.3133]], dtype=torch.float64)\n",
            "Datatype of tensor1: torch.float64\n",
            "Datatype of tensor2: torch.float32\n",
            "Shape of tensor: torch.Size([3, 4])\n",
            "Device tensor1 is on: cpu\n",
            "Device tensor2 is on: cpu\n"
          ]
        }
      ],
      "source": [
        "# Find out information\n",
        "print(test_tensor1)\n",
        "print(f\"Datatype of tensor1: {test_tensor1.dtype}\")\n",
        "print(f\"Datatype of tensor2: {test_tensor2.dtype}\")\n",
        "print(f\"Shape of tensor: {test_tensor1.shape}\")\n",
        "print(f\"Device tensor1 is on: {test_tensor1.device}\")\n",
        "print(f\"Device tensor2 is on: {test_tensor2.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aw1fFZLHw67j"
      },
      "source": [
        "### Manipulating Tensors (Tensor Operations)\n",
        "\n",
        "Tensor operations include:\n",
        "* Addition\n",
        "* Subtraction\n",
        "* Multiplication (element-wise)\n",
        "* Division\n",
        "* Matrix Multiplication"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "vj-aJXKaw67j",
        "outputId": "2ec3f358-88f0-4a4c-a631-0244e2961dc1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([11, 12, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "# Create a tensor\n",
        "tensor = torch.tensor([1, 2, 3], device=device)\n",
        "tensor + 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "e0-_J4KFw67j",
        "outputId": "ed8f8fae-8d64-4c7d-f0a9-477d4aceeb99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# Multiply tensor by 10\n",
        "tensor * 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Gl4LU4U0w67j",
        "outputId": "42d3c4b7-052a-4fcf-d108-11ba078e8983",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-9, -8, -7])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# Subtract by 10\n",
        "tensor - 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "PULh_KYhw67j",
        "outputId": "4f4eda8d-8b80-4e0d-e6e6-c1df22a19ac4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# Try out Pytorch in-built functions\n",
        "torch.mul(tensor, 10) # Generally, you want to use Python functions instead"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "qEkR8-8Nw67j",
        "outputId": "ce70a993-670d-4308-c61f-a44dd85abd28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([11, 12, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "torch.add(tensor, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7oKKOKPw67j"
      },
      "source": [
        "### Matrix Multiplication\n",
        "\n",
        "Two main ways of performing multiplication in neural networks and deep learning:\n",
        "\n",
        "1. Element-wise multiplication\n",
        "2. Matrix multiplication (dot-product)\n",
        "\n",
        "The main two rules for matrix multiplication to remember are:\n",
        "\n",
        "* The inner dimensions must match: \\\\\n",
        "(3, 2) @ (3, 2) won't work \\\\\n",
        "(2, 3) @ (3, 2) will work \\\\\n",
        "(3, 2) @ (2, 3) will work \\\\\n",
        "* The resulting matrix has the shape of the outer dimensions: \\\\\n",
        "(2, 3) @ (3, 2) -> (2, 2) \\\\\n",
        "(3, 2) @ (2, 3) -> (3, 3)\n",
        "\n",
        "```\n",
        "Note: \"@\" in Python is the symbol for matrix multiplication.\n",
        "```\n",
        "```\n",
        "Resource: You can see all of the rules for matrix multiplication using torch.matmul() in the PyTorch documentation.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "O2isiyOWw67j",
        "outputId": "d7237b03-c4b5-4a17-bb5c-7b1d7881d97e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) * tensor(1) tensor(2) tensor(3)\n",
            "Equals: tensor([1, 4, 9])\n"
          ]
        }
      ],
      "source": [
        "# Element-wise multiplication\n",
        "print(tensor, \"*\", * tensor)\n",
        "print(f\"Equals: {tensor * tensor}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "QtSi4Uwlw67j",
        "outputId": "93fafe56-7223-45b1-8526-42f8198393c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14.)"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# Matrix Multiplication\n",
        "\n",
        "tensor = tensor.float() # currently, MPS device only supports float32\n",
        "torch.matmul(tensor, tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "7warxeYxw67j",
        "outputId": "3a49a801-6cee-42e9-97e2-f0b1c701ca44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(14.)\n",
            "CPU times: user 3.37 ms, sys: 0 ns, total: 3.37 ms\n",
            "Wall time: 4.48 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "value = 0\n",
        "for i in range(len(tensor)):\n",
        "    value += tensor[i] * tensor[i]\n",
        "print(value)\n",
        "# Matrix multiplication by hand\n",
        "# Don't use for loops in PyTorch b/c they are computationally expensive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "gn9hlBT6w67j",
        "outputId": "594b3504-eaf2-4a9a-aa35-8065288250a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 399 µs, sys: 59 µs, total: 458 µs\n",
            "Wall time: 743 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14.)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "%%time\n",
        "torch.matmul(tensor, tensor)\n",
        "\n",
        "# we see that the in-built function is much more optimized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "wUy8aryDw67k",
        "outputId": "9df7b84c-7888-4efd-f105-5dd5028206ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2189, 0.3451, 0.4612],\n",
              "        [0.1467, 0.2735, 0.3921],\n",
              "        [0.1746, 0.2502, 0.3185]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "torch.matmul(torch.rand(3, 2, device=device), torch.rand(2, 3, device=device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "VUtIt2YYw67k",
        "outputId": "2e96264c-d4bd-4641-a2c1-30eee0ee84d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.8762, 2.7567, 2.8814],\n",
              "        [2.0462, 3.5475, 3.8082]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "torch.matmul(torch.rand(2, 10, device=device), torch.rand(10, 3, device=device))\n",
        "\n",
        "# remember: resulting matrix has the shape of the outer dimensions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zr-fZKv5w67k"
      },
      "source": [
        "### One of the most common errors in Deep Learning: Shape Errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "3YR7VdhNw67k"
      },
      "outputs": [],
      "source": [
        "# Shapes for matrix multiplication\n",
        "tensor_A = torch.tensor([[1, 2],\n",
        "                         [3, 4],\n",
        "                         [5, 6]])\n",
        "\n",
        "tensor_B = torch.tensor([[7, 10],\n",
        "                         [8, 11],\n",
        "                         [9, 12]])\n",
        "\n",
        "\n",
        "# torch.mm(tensor_A, tensor_B) # torch.mm is the same as torch.matmul (alias)\n",
        "#torch.matmul(tensor_A, tensor_B) # uncomment this to get an error because shapes are incompatible"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "hf98FvTFw67k",
        "outputId": "3d3bf333-4643-4856-c343-5e824e718120",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3, 2]), torch.Size([3, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "# Check tensor sizes to make sure they are compatible for matrix multiplication\n",
        "tensor_A.shape, tensor_B.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwPFHtGgw67k"
      },
      "source": [
        "To fix our tensor shape issues, we can manipulate the shape of one of our tensors using a transpose.\n",
        "\n",
        "A **transpose** switches the axes or dimensions of a given tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "Qpm-aKeiw67k",
        "outputId": "a7b667b7-8762-4f6f-901a-47976bba83fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 7, 10],\n",
              "        [ 8, 11],\n",
              "        [ 9, 12]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "tensor_B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "NOG3sBf0w67k",
        "outputId": "fa0a8d91-4647-4836-c106-8468936b05f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 7,  8,  9],\n",
              "         [10, 11, 12]]),\n",
              " torch.Size([2, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "tensor_B.T, tensor_B.T.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "ZBgRHRXxw67k",
        "outputId": "485587a7-635a-416f-ece7-da1c748fb3ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 7,  8,  9],\n",
              "         [10, 11, 12]]),\n",
              " torch.Size([2, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "# transpose switches the dimensions from 3x2 to 2x3\n",
        "tensor_B.T, tensor_B.T.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "IwfDurA8w67k",
        "outputId": "9db154fa-881c-49da-ca2f-73d31bb730e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([3, 2])\n",
            "\n",
            "New shapes: tensor_A = torch.Size([3, 2]) (same shape as above), tensor_B.T = torch.Size([2, 3])\n",
            "\n",
            "Multiplying: torch.Size([3, 2]) @ torch.Size([2, 3]) <- inner dimensions must match\n",
            "\n",
            "Output:\n",
            "tensor([[ 27,  30,  33],\n",
            "        [ 61,  68,  75],\n",
            "        [ 95, 106, 117]])\n",
            "\n",
            "Output shape: torch.Size([3, 3])\n"
          ]
        }
      ],
      "source": [
        "# The matrix multiplication operation works when tensor_B is transposed\n",
        "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\\n\")\n",
        "print(f\"New shapes: tensor_A = {tensor_A.shape} (same shape as above), tensor_B.T = {tensor_B.T.shape}\\n\")\n",
        "print(f\"Multiplying: {tensor_A.shape} @ {tensor_B.T.shape} <- inner dimensions must match\\n\")\n",
        "print(\"Output:\")\n",
        "output = torch.matmul(tensor_A, tensor_B.T)\n",
        "print(output)\n",
        "print(f\"\\nOutput shape: {output.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SizTHo_Mw67k"
      },
      "source": [
        "## Finding the min, max, mean, sum, etc (tensor aggregation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "TbSgjknDw67l",
        "outputId": "219336aa-30c4-4b48-c4de-5ea4c4079a32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91]), torch.int64)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "# Create a tensor\n",
        "x = torch.arange(1, 100, 10) # torch.arange(start, end, step)\n",
        "x, x.dtype\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "ebfNl4A4w67l",
        "outputId": "8253907d-f378-4d14-a435-7f45430df272",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(1), tensor(1))"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "# Find the min, note that both torch.sum(x) and x.sum() are functionally equivalent\n",
        "torch.min(x), x.min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "9c3iV0gyw67l",
        "outputId": "b1aa1b2b-835b-4025-f8ff-de473de06534",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(91), tensor(91))"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "# Find the max\n",
        "torch.max(x), x.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "1Z6CwTh8w67l",
        "outputId": "35f7cd8e-f0c2-4aad-fe39-a15880d3e42c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(46.), tensor(46.))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "# Find the mean\n",
        "#torch.mean(x), x.mean() # This will result in an error because x is not a float tensor\n",
        "\n",
        "# the torch.mean() function requires a tensor of float32 dtype to work properly\n",
        "torch.mean(x.type(torch.float32)), x.type(torch.float32).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "fuzxyRBGw67l",
        "outputId": "494b2439-71c7-47ac-fcb8-d43d2e3cf32c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(460), tensor(460))"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "# Find the sum\n",
        "torch.sum(x), x.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OEKIr7Hw67l"
      },
      "source": [
        "## Finding the positional min and max"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "dzsAyLEvw67l",
        "outputId": "eb6e03a5-9f7a-40c5-c5d4-e18ab0cc52a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "# Find the position in tensor that has the minimum value with argmin()\n",
        "x.argmin() # This returns index position of target tensor where the minimum value occurs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "y7l_sf-aw67l",
        "outputId": "95e8d374-7c30-495d-ac4d-42308032d3e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "x[0] # This returns the actual minimum value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "aJp0rBA8w67l",
        "outputId": "08fb82ab-bb4d-4628-f8e9-22a11515fe70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(9)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "# Find the position in tensor that has the maximum value with argmax()\n",
        "x. argmax()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "9uogHE5Zw67l",
        "outputId": "03bbfde7-e62b-4c78-b4ba-257938d0f2a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(91)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "x[9] # This returns the actual maximum value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZ9CZyfqw67l"
      },
      "source": [
        "## Reshaping, stacking, squeezing and unsqueezing tensors\n",
        "\n",
        "* Reshaping - reshapes an input tensor into a defined shape\n",
        "* View - return a view of an input tensor of a certain shape but keep the same memory as the original tensor\n",
        "* Stacking - combine multiple tensors on top of each other (vstack) or side by side (hstack)\n",
        "* Squeeze - removes all `1` dimensions from a tensor\n",
        "* Unsqueeze - adds a `1` dimension to a target tensor\n",
        "* Permute - return a view of the input with dimensions permuted (swapped) in a certain way"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "BFaIe3aiw67l",
        "outputId": "b7a34f10-2974-41e4-f7e4-174320231e6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "# Create a tensor\n",
        "x = torch.arange(1., 10.)\n",
        "x, x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "eR8nMvXFw67l",
        "outputId": "28ab3608-93eb-44df-8b8a-21418a0e645d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1.],\n",
              "         [2.],\n",
              "         [3.],\n",
              "         [4.],\n",
              "         [5.],\n",
              "         [6.],\n",
              "         [7.],\n",
              "         [8.],\n",
              "         [9.]]),\n",
              " torch.Size([9, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "# Add an extra dimension to the tensor\n",
        "\n",
        "# x.reshape(dim1, dim2, ..., dimN) # Dimension must have the same number of elements as the original tensor, same number as what torch.Size gives\n",
        "#x_reshaped = x.reshape(1, 7) # Error occurs because reshaping to (1, 7) is invalid as the total number of elements must remain the same.\n",
        "#x_reshaped = x.reshape(2, 9) # Error occurs because this would require 18 elements, but we only have 9.\n",
        "x_reshaped = x.reshape(9, 1)\n",
        "x_reshaped, x_reshaped.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "r0gylx2iw67m",
        "outputId": "d0608556-3b2d-4343-b6c1-e815d55d7322",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "# Change the view\n",
        "z = x.view(1, 9)\n",
        "z, z.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "ZCXSkPBlw67m",
        "outputId": "f26095e5-4023-49ff-f84c-42e78f26aad3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
              " tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]))"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "# Changing z changes x (because a view of a tensor shares the same memory as the original tensor)\n",
        "z[:, 0] = 5 # This changes the first element of z to 5\n",
        "z, x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "A_7vA0G8w67m",
        "outputId": "d8eef7d5-6d3b-4499-e341-c312b9692c58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "        [5., 2., 3., 4., 5., 6., 7., 8., 9.]])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "# Stack tensors on top of each other\n",
        "\n",
        "# Stack tensors on top of each other along the first dimension (rows), creating a 2D tensor.\n",
        "x_stacked = torch.stack([x, x, x, x], dim=0)\n",
        "\n",
        "# Stack tensors side by side along the second dimension (columns), creating a 2D tensor.\n",
        "#x_stacked = torch.stack([x, x, x, x], dim=1)\n",
        "\n",
        "# Attempt to stack tensors along the third dimension, but this will result in an error for 1D tensors.\n",
        "#x_stacked = torch.stack([x, x, x, x], dim=2)\n",
        "\n",
        "x_stacked\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "bkyfcD70w67m",
        "outputId": "3282ebac-4b9e-47d8-8c0f-c5c6d5af8ff8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous tensor: tensor([[5.],\n",
            "        [2.],\n",
            "        [3.],\n",
            "        [4.],\n",
            "        [5.],\n",
            "        [6.],\n",
            "        [7.],\n",
            "        [8.],\n",
            "        [9.]])\n",
            "Previous shape: torch.Size([9, 1])\n",
            "\n",
            "New tensor: tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
            "New shape: torch.Size([9])\n"
          ]
        }
      ],
      "source": [
        "# torch.squeeze(input, dim=None) - removes all single dimensions from a target tensor\n",
        "print(f\"Previous tensor: {x_reshaped}\")\n",
        "print(f\"Previous shape: {x_reshaped.shape}\")\n",
        "\n",
        "# Remove extra dimensions from x_reshaped\n",
        "x_squeezed = x_reshaped.squeeze()\n",
        "print(f\"\\nNew tensor: {x_squeezed}\")\n",
        "print(f\"New shape: {x_squeezed.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "GYOzUkEOw67m",
        "outputId": "16318433-ac1f-4f0e-b525-41013acaa00b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous target: tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
            "Previous shape: torch.Size([9])\n",
            "\n",
            "New tensor: tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])\n",
            "New shape: torch.Size([1, 9])\n"
          ]
        }
      ],
      "source": [
        "# torch.unsqueeze(input, dim) - adds a single dimension to a target tensor at a specific dim\n",
        "print(f\"Previous target: {x_squeezed}\")\n",
        "print(f\"Previous shape: {x_squeezed.shape}\")\n",
        "\n",
        "# Add an extra dimension with unsqueeze\n",
        "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
        "print(f\"\\nNew tensor: {x_unsqueezed}\")\n",
        "print(f\"New shape: {x_unsqueezed.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "_WySFZnTw67m",
        "outputId": "ae915cf5-7254-470b-f0fb-7ad1728edf3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous target: tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.])\n",
            "Previous shape: torch.Size([9])\n",
            "\n",
            "New tensor: \n",
            "tensor([[5.],\n",
            "        [2.],\n",
            "        [3.],\n",
            "        [4.],\n",
            "        [5.],\n",
            "        [6.],\n",
            "        [7.],\n",
            "        [8.],\n",
            "        [9.]])\n",
            "New shape: torch.Size([9, 1])\n"
          ]
        }
      ],
      "source": [
        "# torch.unsqueeze(input, dim) - adds a single dimension to a target tensor at a specific dim\n",
        "print(f\"Previous target: {x_squeezed}\")\n",
        "print(f\"Previous shape: {x_squeezed.shape}\")\n",
        "\n",
        "# Add an extra dimension with unsqueeze\n",
        "x_unsqueezed = x_squeezed.unsqueeze(dim=1)\n",
        "print(f\"\\nNew tensor: \\n{x_unsqueezed}\")\n",
        "print(f\"New shape: {x_unsqueezed.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "H5ct8ysIw67m",
        "outputId": "ae51f4f3-9bf9-47d8-940b-592ef2f6216e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous shape: torch.Size([224, 224, 3])\n",
            "New shape: torch.Size([3, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "# torch.permute - rearranges the dimensions of a target tensor of a specified order\n",
        "x_original = torch.rand(size=(224, 224, 3)) # [height, width, color_channels]\n",
        "\n",
        "# Permute the original tensor to rearrange the axis order\n",
        "x_permuted = x_original.permute(2, 0, 1) # shifts axis 0->1, 1->2, 2->0\n",
        "\n",
        "print(f\"Previous shape: {x_original.shape}\")\n",
        "print(f\"New shape: {x_permuted.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iw7Sck5aw67m"
      },
      "source": [
        "Remember the purpose of reshaping, stacking, squeezing, and unsqueezing tensors: these help us fix shape and dimension issues with tensors, which is the most common error in Deep Learning and Neural Networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDkh6uLSw67m"
      },
      "source": [
        "## Indexing (selecting data from tensors)\n",
        "\n",
        "Indexing with PyTorch is similar to indexing with NumPy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "flJcPVyRw67m",
        "outputId": "783df8d9-5755-42c7-a4ec-635bf641f123",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[1, 2, 3],\n",
              "          [4, 5, 6],\n",
              "          [7, 8, 9]]]),\n",
              " torch.Size([1, 3, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "# Create a tensor\n",
        "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
        "x, x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "xE1hP312w67m",
        "outputId": "2603a21b-4f6b-4dda-ddb7-a3e97a6b8f39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1, 2, 3],\n",
              "         [4, 5, 6],\n",
              "         [7, 8, 9]]),\n",
              " torch.Size([3, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "# Let's index on our new tensor\n",
        "x[0], x[0].shape # Indexing on the first dimension (batch dimension)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "Xyp_9GyUw67m",
        "outputId": "5280b716-411f-4ba8-a463-e43966db9e03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1, 2, 3]), torch.Size([3]))"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "# Let's index on the middle bracket (dim=1)\n",
        "x[0][0], x[0][0].shape # Indexing on the second dimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "G71VsKvFw67m",
        "outputId": "27523ad1-e016-46a1-bf81-c99664a425ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(1), torch.Size([]))"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "# Let's index on the most inner bracket (last dimension)\n",
        "x[0][0][0], x[0][0][0].shape # Indexing on the third dimension\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "8GKphRCWw67n",
        "outputId": "991f1aa4-a0a2-424f-85b2-ba14fadc1bec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(9), torch.Size([]))"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "# Play around with the indexing!\n",
        "x[0][2][2], x[0][2][2].shape # note that for our current tensor, x[1][0][0] will give us an error b/c the index is out of bounds for current tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "k-I9x96_w67n",
        "outputId": "3551935b-fa10-4c6b-868f-979630158b52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "# You can also use \":\" to select \"all\" of a target dimension\n",
        "x[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "aGEXzL6fw67n",
        "outputId": "3364cc80-513d-420f-b77c-21346aed2a7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 5, 8]])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "# Get all values across the 0th and 1st dimensions, but only the 2nd index of the 2nd dimension\n",
        "x[:, :, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "IgW1lVXBw67n",
        "outputId": "8b417de4-acce-4391-f748-3eacdab3b057",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "# Get all values across the 0th dimension, but only the 1 index value of 1st and 2nd dimension\n",
        "x[:, 1, 1] # retrieves all elements from 0th dimension, grabs the element at index 1 in 1st dimension, grabs the element at index 1 in 2nd dimension\n",
        "\n",
        "# Note that this is very similar to x[0][1][1] except we have an extra dimension [ ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "hskSBaaiw67n",
        "outputId": "89f26c45-727b-44ef-845c-0737b43917f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "# Get all values across the 0th dimension, but only the 1 index value of 1st and 2nd dimension\n",
        "x[:, 1, 1] # retrieves all elements from 0th dimension, grabs the element at index 1 in 1st dimension, grabs the element at index 1 in 2nd dimension\n",
        "\n",
        "# Note that this is very similar to x[0][1][1] except we have an extra dimension [ ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "yvxAsiufw67n",
        "outputId": "747a9659-7a77-44cd-e5c6-cb23f4365f37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "# Get index 0 of 0th and 1st dimension and all values of 2nd dimension\n",
        "x[0, 0, :] # equivalent to x[0][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbvjuTupw67n"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}